2022-11-02 04:44:07 | INFO | fairseq.distributed.utils | distributed init (rank 0): tcp://localhost:16870
2022-11-02 04:44:07 | INFO | fairseq.distributed.utils | distributed init (rank 2): tcp://localhost:16870
2022-11-02 04:44:07 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 2
2022-11-02 04:44:07 | INFO | fairseq.distributed.utils | distributed init (rank 1): tcp://localhost:16870
2022-11-02 04:44:07 | INFO | fairseq.distributed.utils | distributed init (rank 3): tcp://localhost:16870
2022-11-02 04:44:07 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 1
2022-11-02 04:44:07 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 3
2022-11-02 04:44:07 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:1 to store for rank: 0
2022-11-02 04:44:07 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2022-11-02 04:44:07 | INFO | fairseq.distributed.utils | initialized host scn32-mn as rank 0
2022-11-02 04:44:07 | INFO | torch.distributed.distributed_c10d | Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2022-11-02 04:44:07 | INFO | fairseq.distributed.utils | initialized host scn32-mn as rank 2
2022-11-02 04:44:07 | INFO | torch.distributed.distributed_c10d | Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2022-11-02 04:44:07 | INFO | torch.distributed.distributed_c10d | Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2022-11-02 04:44:07 | INFO | fairseq.distributed.utils | initialized host scn32-mn as rank 1
2022-11-02 04:44:07 | INFO | fairseq.distributed.utils | initialized host scn32-mn as rank 3
2022-11-02 04:44:22 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': 'Indic-En-Distillation', 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': 'indicTrans/model_configs', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 4, 'distributed_num_procs': 4, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'tcp://localhost:16870', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 4, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 64, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 16384, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 16384, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 1000000, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints/adaptive-distil', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': 5, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 4}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project='Indic-En-Distillation', azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=True, memory_efficient_fp16=True, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir='indicTrans/model_configs', empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy_with_kd', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', scoring='bleu', task='translation', num_workers=64, skip_invalid_size_inputs_valid_test=True, max_tokens=16384, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=16384, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=4, distributed_num_procs=4, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=4, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='transformer', max_epoch=0, max_update=1000000, stop_time_hours=0, clip_norm=1.0, sentence_avg=False, update_freq=[1], lr=[0.0005], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, save_dir='checkpoints/adaptive-distil', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=5, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, data='indic-en-exp/final_bin', source_lang='SRC', target_lang='TGT', load_alignments=False, left_pad_source=True, left_pad_target=False, upsample_primary=-1, truncate_source=False, num_batch_buckets=0, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_tokenized_bleu=False, eval_bleu_remove_bpe=None, eval_bleu_print_samples=False, kd_strategy='word_and_seq_level', teacher_checkpoint_path='checkpoints/indicTrans/checkpoint_best.pt', label_smoothing=0.1, report_accuracy=False, ignore_prefix_size=0, kd_rate=None, kd_queue_size=20000, student_temp=1, teacher_temp=1, alpha=None, use_adaptive_weightage=True, adaptive_smoothing=0.5, use_adaptive_kd_rates=False, kd_selection_temp=None, adam_betas='(0.9, 0.98)', adam_eps=1e-08, weight_decay=0.0, use_old_adam=False, fp16_adam_stats=False, warmup_updates=4000, warmup_init_lr=1e-07, pad=1, eos=2, unk=3, max_source_positions=210, max_target_positions=210, activation_fn='gelu', layernorm_embedding=True, decoder_normalize_before=True, encoder_normalize_before=True, dropout=0.2, no_seed_provided=False, encoder_embed_path=None, encoder_embed_dim=512, encoder_ffn_embed_dim=2048, encoder_layers=6, encoder_attention_heads=8, encoder_learned_pos=False, decoder_embed_path=None, decoder_embed_dim=512, decoder_ffn_embed_dim=2048, decoder_layers=6, decoder_attention_heads=8, decoder_learned_pos=False, attention_dropout=0.0, activation_dropout=0.0, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, share_decoder_input_output_embed=False, share_all_embeddings=False, merge_src_tgt_embed=False, no_token_positional_embeddings=False, adaptive_input=False, no_cross_attention=False, cross_self_attention=False, decoder_output_dim=512, decoder_input_dim=512, no_scale_embedding=False, tie_adaptive_weights=False, checkpoint_activations=False, offload_activations=False, encoder_layers_to_keep=None, decoder_layers_to_keep=None, encoder_layerdrop=0, decoder_layerdrop=0, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, _name='transformer'), 'task': {'_name': 'translation', 'data': 'indic-en-exp/final_bin', 'source_lang': 'SRC', 'target_lang': 'TGT', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 210, 'max_target_positions': 210, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False, 'kd_strategy': 'word_and_seq_level', 'teacher_checkpoint_path': 'checkpoints/indicTrans/checkpoint_best.pt'}, 'criterion': {'_name': 'label_smoothed_cross_entropy_with_kd', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'kd_rate': None, 'kd_queue_size': 20000, 'student_temp': 1.0, 'teacher_temp': 1.0, 'alpha': None, 'use_adaptive_weightage': True, 'adaptive_smoothing': 0.5, 'use_adaptive_kd_rates': False, 'kd_selection_temp': None, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': 1e-07, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}
2022-11-02 04:44:22 | INFO | fairseq.tasks.translation | [SRC] dictionary: 35904 types
2022-11-02 04:44:22 | INFO | fairseq.tasks.translation | [TGT] dictionary: 32088 types
2022-11-02 04:44:24 | INFO | fairseq_cli.train | TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(35904, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layernorm_embedding): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(32088, 512, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layernorm_embedding): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=512, out_features=512, bias=True)
          (v_proj): Linear(in_features=512, out_features=512, bias=True)
          (q_proj): Linear(in_features=512, out_features=512, bias=True)
          (out_proj): Linear(in_features=512, out_features=512, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=512, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=512, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): FusedLayerNorm(torch.Size([512]), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=512, out_features=32088, bias=False)
  )
)
2022-11-02 04:44:24 | INFO | fairseq_cli.train | task: TranslationTask
2022-11-02 04:44:24 | INFO | fairseq_cli.train | model: TransformerModel
2022-11-02 04:44:24 | INFO | fairseq_cli.train | criterion: KDLabelSmoothedCrossEntropyCriterion
2022-11-02 04:44:24 | INFO | fairseq_cli.train | num. shared model params: 95,383,552 (num. trained: 95,383,552)
2022-11-02 04:44:24 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2022-11-02 04:44:24 | INFO | fairseq.data.data_utils | loaded 78,941 examples from: indic-en-exp/final_bin/valid.SRC-TGT.SRC
2022-11-02 04:44:24 | INFO | fairseq.data.data_utils | loaded 78,941 examples from: indic-en-exp/final_bin/valid.SRC-TGT.TGT
2022-11-02 04:44:24 | INFO | fairseq.tasks.translation | indic-en-exp/final_bin valid SRC-TGT 78941 examples
2022-11-02 04:44:27 | INFO | torch.distributed.distributed_c10d | Added key: store_based_barrier_key:2 to store for rank: 0
2022-11-02 04:44:29 | INFO | torch.distributed.distributed_c10d | Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 4 nodes.
2022-11-02 04:44:30 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2022-11-02 04:44:30 | INFO | fairseq.utils | rank   0: capabilities =  8.0  ; total memory = 39.587 GB ; name = A100-SXM4-40GB                          
2022-11-02 04:44:30 | INFO | fairseq.utils | rank   1: capabilities =  8.0  ; total memory = 39.587 GB ; name = A100-SXM4-40GB                          
2022-11-02 04:44:30 | INFO | fairseq.utils | rank   2: capabilities =  8.0  ; total memory = 39.587 GB ; name = A100-SXM4-40GB                          
2022-11-02 04:44:30 | INFO | fairseq.utils | rank   3: capabilities =  8.0  ; total memory = 39.587 GB ; name = A100-SXM4-40GB                          
2022-11-02 04:44:30 | INFO | fairseq.utils | ***********************CUDA enviroments for all 4 workers***********************
2022-11-02 04:44:30 | INFO | fairseq_cli.train | training on 4 devices (GPUs/TPUs)
2022-11-02 04:44:30 | INFO | fairseq_cli.train | max tokens per device = 16384 and max sentences per device = None
2022-11-02 04:44:30 | INFO | fairseq.trainer | Preparing to load checkpoint checkpoints/adaptive-distil/checkpoint_last.pt
2022-11-02 04:44:38 | INFO | fairseq.optim.adam | using FusedAdam
2022-11-02 04:44:52 | INFO | fairseq.trainer | Loaded checkpoint checkpoints/adaptive-distil/checkpoint_last.pt (epoch 14 @ 208318 updates)
2022-11-02 04:44:52 | INFO | fairseq.trainer | loading train data for epoch 14
2022-11-02 04:44:53 | INFO | fairseq.data.data_utils | loaded 49,772,565 examples from: indic-en-exp/final_bin/train.SRC-TGT.SRC
2022-11-02 04:44:56 | INFO | fairseq.data.data_utils | loaded 49,772,565 examples from: indic-en-exp/final_bin/train.SRC-TGT.TGT
2022-11-02 04:44:56 | INFO | fairseq.tasks.translation | indic-en-exp/final_bin train SRC-TGT 49772565 examples
2022-11-02 04:45:13 | WARNING | fairseq.tasks.fairseq_task | 11,612 samples have invalid sizes and will be skipped, max_positions=(210, 210), first few sample ids=[38134819, 6246747, 2525593, 1919047, 33622048, 7799562, 4508869, 12466026, 14778728, 20258840]
2022-11-02 04:45:13 | WARNING | fairseq.tasks.fairseq_task | 11,612 samples have invalid sizes and will be skipped, max_positions=(210, 210), first few sample ids=[38134819, 6246747, 2525593, 1919047, 33622048, 7799562, 4508869, 12466026, 14778728, 20258840]
2022-11-02 04:45:16 | WARNING | fairseq.tasks.fairseq_task | 11,612 samples have invalid sizes and will be skipped, max_positions=(210, 210), first few sample ids=[38134819, 6246747, 2525593, 1919047, 33622048, 7799562, 4508869, 12466026, 14778728, 20258840]
2022-11-02 04:45:17 | WARNING | fairseq.tasks.fairseq_task | 11,612 samples have invalid sizes and will be skipped, max_positions=(210, 210), first few sample ids=[38134819, 6246747, 2525593, 1919047, 33622048, 7799562, 4508869, 12466026, 14778728, 20258840]
2022-11-02 04:45:40 | INFO | fairseq_cli.train | loaded teacher model TransformerModel(
  (encoder): TransformerEncoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(35904, 1536, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1536]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1536, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1536, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1536]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1536]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1536, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1536, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1536]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1536]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1536, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1536, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1536]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1536]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1536, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1536, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1536]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1536]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1536, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1536, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1536]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerEncoderLayerBase(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
        )
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1536]), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1536, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1536, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1536]), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderBase(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(32088, 1536, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1536]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([1536]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1536, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1536, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1536]), eps=1e-05, elementwise_affine=True)
      )
      (1): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1536]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([1536]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1536, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1536, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1536]), eps=1e-05, elementwise_affine=True)
      )
      (2): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1536]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([1536]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1536, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1536, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1536]), eps=1e-05, elementwise_affine=True)
      )
      (3): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1536]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([1536]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1536, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1536, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1536]), eps=1e-05, elementwise_affine=True)
      )
      (4): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1536]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([1536]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1536, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1536, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1536]), eps=1e-05, elementwise_affine=True)
      )
      (5): TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1536]), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (v_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (q_proj): Linear(in_features=1536, out_features=1536, bias=True)
          (out_proj): Linear(in_features=1536, out_features=1536, bias=True)
        )
        (encoder_attn_layer_norm): FusedLayerNorm(torch.Size([1536]), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1536, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1536, bias=True)
        (final_layer_norm): FusedLayerNorm(torch.Size([1536]), eps=1e-05, elementwise_affine=True)
      )
    )
    (output_projection): Linear(in_features=1536, out_features=32088, bias=False)
  )
) from checkpoints/indicTrans/checkpoint_best.pt in evaluation mode
2022-11-02 04:45:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 16028
2022-11-02 04:45:48 | INFO | fairseq.trainer | begin training epoch 14
2022-11-02 04:45:48 | INFO | fairseq_cli.train | Start iterating over samples
2022-11-02 04:46:43 | WARNING | urllib3.connectionpool | Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden'))': /api/5288891/envelope/
2022-11-02 04:46:43 | WARNING | urllib3.connectionpool | Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden'))': /api/5288891/envelope/
2022-11-02 04:46:43 | WARNING | urllib3.connectionpool | Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('Cannot connect to proxy.', OSError('Tunnel connection failed: 403 Forbidden'))': /api/5288891/envelope/
2022-11-02 04:53:47 | INFO | torch.nn.parallel.distributed | Reducer buckets have been rebuilt in this iteration.
2022-11-02 04:55:34 | INFO | train_inner | epoch 014:     82 / 16028 loss=2.95, nll_loss=0.984, nll_loss_teacher=0.547, kd_loss=3.254, ppl=1.98, wps=35278.8, ups=0.75, wpb=46656.1, bsz=3159.4, num_updates=208400, lr=6.92709e-05, gnorm=0.289, clip=0, loss_scale=16, train_wall=110, gb_free=29.5, wall=664
2022-11-02 04:57:41 | INFO | train_inner | epoch 014:    182 / 16028 loss=2.948, nll_loss=0.986, nll_loss_teacher=0.542, kd_loss=3.245, ppl=1.98, wps=36326, ups=0.79, wpb=46025.5, bsz=3115.8, num_updates=208500, lr=6.92543e-05, gnorm=0.295, clip=0, loss_scale=16, train_wall=126, gb_free=24.3, wall=790
2022-11-02 04:59:47 | INFO | train_inner | epoch 014:    282 / 16028 loss=2.944, nll_loss=0.979, nll_loss_teacher=0.542, kd_loss=3.242, ppl=1.97, wps=36658.7, ups=0.79, wpb=46266.6, bsz=3088.7, num_updates=208600, lr=6.92377e-05, gnorm=0.282, clip=0, loss_scale=16, train_wall=126, gb_free=26.2, wall=917
2022-11-02 05:01:54 | INFO | train_inner | epoch 014:    382 / 16028 loss=2.951, nll_loss=0.986, nll_loss_teacher=0.544, kd_loss=3.25, ppl=1.98, wps=35893.5, ups=0.79, wpb=45548.2, bsz=3032.1, num_updates=208700, lr=6.92211e-05, gnorm=0.29, clip=0, loss_scale=16, train_wall=127, gb_free=23, wall=1044
2022-11-02 05:04:05 | INFO | train_inner | epoch 014:    482 / 16028 loss=2.958, nll_loss=0.994, nll_loss_teacher=0.542, kd_loss=3.256, ppl=1.99, wps=35156.4, ups=0.77, wpb=45906.2, bsz=2998.1, num_updates=208800, lr=6.92046e-05, gnorm=0.29, clip=0, loss_scale=16, train_wall=130, gb_free=23.7, wall=1174
2022-11-02 05:06:22 | INFO | train_inner | epoch 014:    582 / 16028 loss=2.96, nll_loss=0.998, nll_loss_teacher=0.544, kd_loss=3.255, ppl=2, wps=33498.6, ups=0.73, wpb=45931.1, bsz=3087.3, num_updates=208900, lr=6.9188e-05, gnorm=0.294, clip=0, loss_scale=16, train_wall=137, gb_free=18.1, wall=1311
2022-11-02 05:08:38 | INFO | train_inner | epoch 014:    682 / 16028 loss=2.964, nll_loss=0.997, nll_loss_teacher=0.547, kd_loss=3.261, ppl=2, wps=33608.5, ups=0.74, wpb=45702.2, bsz=3094.6, num_updates=209000, lr=6.91714e-05, gnorm=0.296, clip=0, loss_scale=16, train_wall=136, gb_free=18.8, wall=1447
2022-11-02 05:10:56 | INFO | train_inner | epoch 014:    782 / 16028 loss=2.953, nll_loss=0.989, nll_loss_teacher=0.542, kd_loss=3.248, ppl=1.99, wps=33194.5, ups=0.72, wpb=45816, bsz=3118.9, num_updates=209100, lr=6.91549e-05, gnorm=0.295, clip=0, loss_scale=16, train_wall=138, gb_free=21.4, wall=1585
2022-11-02 05:13:13 | INFO | train_inner | epoch 014:    882 / 16028 loss=2.96, nll_loss=0.994, nll_loss_teacher=0.545, kd_loss=3.261, ppl=1.99, wps=32881, ups=0.73, wpb=45278.1, bsz=3017.4, num_updates=209200, lr=6.91384e-05, gnorm=0.303, clip=0, loss_scale=16, train_wall=138, gb_free=21.5, wall=1723
2022-11-02 05:15:32 | INFO | train_inner | epoch 014:    982 / 16028 loss=2.945, nll_loss=0.984, nll_loss_teacher=0.539, kd_loss=3.233, ppl=1.98, wps=33547.2, ups=0.72, wpb=46429.4, bsz=3151.4, num_updates=209300, lr=6.91219e-05, gnorm=0.294, clip=0, loss_scale=16, train_wall=138, gb_free=20.6, wall=1861
2022-11-02 05:17:50 | INFO | train_inner | epoch 014:   1082 / 16028 loss=2.955, nll_loss=0.992, nll_loss_teacher=0.54, kd_loss=3.241, ppl=1.99, wps=33471.7, ups=0.73, wpb=46113.8, bsz=3033.2, num_updates=209400, lr=6.91053e-05, gnorm=0.297, clip=0, loss_scale=16, train_wall=138, gb_free=26.8, wall=1999
2022-11-02 05:20:09 | INFO | train_inner | epoch 014:   1182 / 16028 loss=2.961, nll_loss=0.997, nll_loss_teacher=0.549, kd_loss=3.265, ppl=2, wps=31648.2, ups=0.72, wpb=44178.7, bsz=3178.1, num_updates=209500, lr=6.90889e-05, gnorm=0.31, clip=0, loss_scale=16, train_wall=139, gb_free=22.6, wall=2139
2022-11-02 05:22:28 | INFO | train_inner | epoch 014:   1282 / 16028 loss=2.964, nll_loss=0.999, nll_loss_teacher=0.547, kd_loss=3.259, ppl=2, wps=33832.8, ups=0.72, wpb=47030.8, bsz=2869.4, num_updates=209600, lr=6.90724e-05, gnorm=0.29, clip=0, loss_scale=16, train_wall=139, gb_free=17.6, wall=2278
2022-11-02 05:24:46 | INFO | train_inner | epoch 014:   1382 / 16028 loss=2.948, nll_loss=0.986, nll_loss_teacher=0.54, kd_loss=3.237, ppl=1.98, wps=32642, ups=0.73, wpb=44988.2, bsz=3138.3, num_updates=209700, lr=6.90559e-05, gnorm=0.301, clip=0, loss_scale=16, train_wall=138, gb_free=18.2, wall=2416
2022-11-02 05:27:03 | INFO | train_inner | epoch 014:   1482 / 16028 loss=2.953, nll_loss=0.992, nll_loss_teacher=0.542, kd_loss=3.247, ppl=1.99, wps=33266, ups=0.73, wpb=45585.4, bsz=3228.3, num_updates=209800, lr=6.90394e-05, gnorm=0.307, clip=0, loss_scale=16, train_wall=137, gb_free=23.7, wall=2553
2022-11-02 05:29:20 | INFO | train_inner | epoch 014:   1582 / 16028 loss=2.955, nll_loss=0.992, nll_loss_teacher=0.542, kd_loss=3.248, ppl=1.99, wps=33130.6, ups=0.73, wpb=45375.7, bsz=3111.1, num_updates=209900, lr=6.9023e-05, gnorm=0.297, clip=0, loss_scale=16, train_wall=137, gb_free=19.1, wall=2690
2022-11-02 05:31:37 | INFO | train_inner | epoch 014:   1682 / 16028 loss=2.951, nll_loss=0.989, nll_loss_teacher=0.544, kd_loss=3.247, ppl=1.98, wps=33882, ups=0.73, wpb=46265.4, bsz=3106, num_updates=210000, lr=6.90066e-05, gnorm=0.293, clip=0, loss_scale=16, train_wall=136, gb_free=16.6, wall=2826
2022-11-02 05:33:54 | INFO | train_inner | epoch 014:   1782 / 16028 loss=2.956, nll_loss=0.994, nll_loss_teacher=0.543, kd_loss=3.25, ppl=1.99, wps=33424.1, ups=0.73, wpb=45800.8, bsz=3165, num_updates=210100, lr=6.89901e-05, gnorm=0.294, clip=0, loss_scale=16, train_wall=137, gb_free=16.5, wall=2963
2022-11-02 05:36:06 | INFO | train_inner | epoch 014:   1882 / 16028 loss=2.951, nll_loss=0.99, nll_loss_teacher=0.541, kd_loss=3.245, ppl=1.99, wps=34544.6, ups=0.75, wpb=45880.4, bsz=3234.9, num_updates=210200, lr=6.89737e-05, gnorm=0.305, clip=0, loss_scale=16, train_wall=133, gb_free=23.8, wall=3096
2022-11-02 05:38:24 | INFO | train_inner | epoch 014:   1982 / 16028 loss=2.945, nll_loss=0.986, nll_loss_teacher=0.538, kd_loss=3.233, ppl=1.98, wps=33284.1, ups=0.72, wpb=45920.5, bsz=3225.1, num_updates=210300, lr=6.89573e-05, gnorm=0.293, clip=0, loss_scale=16, train_wall=138, gb_free=24, wall=3234
2022-11-02 05:40:42 | INFO | train_inner | epoch 014:   2082 / 16028 loss=2.961, nll_loss=0.995, nll_loss_teacher=0.544, kd_loss=3.261, ppl=1.99, wps=33036.4, ups=0.73, wpb=45387.2, bsz=3006.1, num_updates=210400, lr=6.89409e-05, gnorm=0.296, clip=0, loss_scale=16, train_wall=137, gb_free=19.3, wall=3371
2022-11-02 05:42:27 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-11-02 05:43:01 | INFO | train_inner | epoch 014:   2183 / 16028 loss=2.952, nll_loss=0.986, nll_loss_teacher=0.545, kd_loss=3.258, ppl=1.98, wps=32961.4, ups=0.72, wpb=45953, bsz=3072.2, num_updates=210500, lr=6.89246e-05, gnorm=0.295, clip=0, loss_scale=8, train_wall=139, gb_free=20, wall=3511
2022-11-02 05:45:19 | INFO | train_inner | epoch 014:   2283 / 16028 loss=2.948, nll_loss=0.989, nll_loss_teacher=0.539, kd_loss=3.237, ppl=1.99, wps=33437.8, ups=0.72, wpb=46219, bsz=3241.2, num_updates=210600, lr=6.89082e-05, gnorm=0.299, clip=0, loss_scale=8, train_wall=138, gb_free=18.7, wall=3649
2022-11-02 05:47:36 | INFO | train_inner | epoch 014:   2383 / 16028 loss=2.955, nll_loss=0.992, nll_loss_teacher=0.543, kd_loss=3.252, ppl=1.99, wps=32987.4, ups=0.73, wpb=45212.5, bsz=3121.5, num_updates=210700, lr=6.88918e-05, gnorm=0.302, clip=0, loss_scale=8, train_wall=137, gb_free=18.1, wall=3786
2022-11-02 05:49:54 | INFO | train_inner | epoch 014:   2483 / 16028 loss=2.96, nll_loss=1, nll_loss_teacher=0.54, kd_loss=3.247, ppl=2, wps=32485.4, ups=0.73, wpb=44771, bsz=3155.3, num_updates=210800, lr=6.88755e-05, gnorm=0.313, clip=0, loss_scale=8, train_wall=138, gb_free=16.6, wall=3924
2022-11-02 05:52:12 | INFO | train_inner | epoch 014:   2583 / 16028 loss=2.956, nll_loss=0.993, nll_loss_teacher=0.544, kd_loss=3.253, ppl=1.99, wps=33357, ups=0.73, wpb=45943.2, bsz=3118.2, num_updates=210900, lr=6.88592e-05, gnorm=0.295, clip=0, loss_scale=8, train_wall=138, gb_free=19.9, wall=4062
2022-11-02 05:54:28 | INFO | train_inner | epoch 014:   2683 / 16028 loss=2.963, nll_loss=1.002, nll_loss_teacher=0.541, kd_loss=3.252, ppl=2, wps=33181.6, ups=0.73, wpb=45190.4, bsz=2925.3, num_updates=211000, lr=6.88428e-05, gnorm=0.3, clip=0, loss_scale=8, train_wall=136, gb_free=16.5, wall=4198
2022-11-02 05:56:45 | INFO | train_inner | epoch 014:   2783 / 16028 loss=2.957, nll_loss=0.997, nll_loss_teacher=0.538, kd_loss=3.239, ppl=2, wps=34041.8, ups=0.73, wpb=46743.1, bsz=3195.3, num_updates=211100, lr=6.88265e-05, gnorm=0.301, clip=0, loss_scale=8, train_wall=137, gb_free=18.9, wall=4335
2022-11-02 05:59:03 | INFO | train_inner | epoch 014:   2883 / 16028 loss=2.959, nll_loss=0.997, nll_loss_teacher=0.543, kd_loss=3.246, ppl=2, wps=32635.9, ups=0.73, wpb=44829.8, bsz=3070.6, num_updates=211200, lr=6.88102e-05, gnorm=0.307, clip=0, loss_scale=8, train_wall=137, gb_free=28.1, wall=4472
2022-11-02 06:01:22 | INFO | train_inner | epoch 014:   2983 / 16028 loss=2.959, nll_loss=0.998, nll_loss_teacher=0.538, kd_loss=3.242, ppl=2, wps=33395.6, ups=0.72, wpb=46383, bsz=2976.5, num_updates=211300, lr=6.8794e-05, gnorm=0.297, clip=0, loss_scale=8, train_wall=139, gb_free=17.4, wall=4611
2022-11-02 06:03:39 | INFO | train_inner | epoch 014:   3083 / 16028 loss=2.957, nll_loss=0.995, nll_loss_teacher=0.545, kd_loss=3.25, ppl=1.99, wps=33408.9, ups=0.73, wpb=45816.8, bsz=3150.9, num_updates=211400, lr=6.87777e-05, gnorm=0.295, clip=0, loss_scale=8, train_wall=137, gb_free=20.8, wall=4749
2022-11-02 06:05:55 | INFO | train_inner | epoch 014:   3183 / 16028 loss=2.957, nll_loss=0.995, nll_loss_teacher=0.543, kd_loss=3.251, ppl=1.99, wps=33162.1, ups=0.73, wpb=45297.8, bsz=3202, num_updates=211500, lr=6.87614e-05, gnorm=0.3, clip=0, loss_scale=8, train_wall=136, gb_free=17.4, wall=4885
2022-11-02 06:08:14 | INFO | train_inner | epoch 014:   3283 / 16028 loss=2.959, nll_loss=0.999, nll_loss_teacher=0.539, kd_loss=3.243, ppl=2, wps=33084.7, ups=0.72, wpb=45773.8, bsz=3076.1, num_updates=211600, lr=6.87452e-05, gnorm=0.306, clip=0, loss_scale=8, train_wall=138, gb_free=16.4, wall=5023
2022-11-02 06:10:31 | INFO | train_inner | epoch 014:   3383 / 16028 loss=2.954, nll_loss=0.992, nll_loss_teacher=0.54, kd_loss=3.245, ppl=1.99, wps=33616.7, ups=0.73, wpb=45941.6, bsz=3092.1, num_updates=211700, lr=6.87289e-05, gnorm=0.303, clip=0, loss_scale=8, train_wall=136, gb_free=24.7, wall=5160
2022-11-02 06:12:48 | INFO | train_inner | epoch 014:   3483 / 16028 loss=2.958, nll_loss=0.998, nll_loss_teacher=0.54, kd_loss=3.249, ppl=2, wps=32870.1, ups=0.73, wpb=45152.7, bsz=3088.8, num_updates=211800, lr=6.87127e-05, gnorm=0.308, clip=0, loss_scale=8, train_wall=137, gb_free=26.6, wall=5298
2022-11-02 06:15:05 | INFO | train_inner | epoch 014:   3583 / 16028 loss=2.954, nll_loss=0.991, nll_loss_teacher=0.544, kd_loss=3.254, ppl=1.99, wps=33307.6, ups=0.73, wpb=45804.2, bsz=3201.8, num_updates=211900, lr=6.86965e-05, gnorm=0.295, clip=0, loss_scale=8, train_wall=137, gb_free=17.7, wall=5435
2022-11-02 06:17:23 | INFO | train_inner | epoch 014:   3683 / 16028 loss=2.954, nll_loss=0.99, nll_loss_teacher=0.542, kd_loss=3.25, ppl=1.99, wps=33578, ups=0.73, wpb=46166.7, bsz=3019.7, num_updates=212000, lr=6.86803e-05, gnorm=0.288, clip=0, loss_scale=8, train_wall=137, gb_free=18.1, wall=5573
2022-11-02 06:19:39 | INFO | train_inner | epoch 014:   3783 / 16028 loss=2.951, nll_loss=0.986, nll_loss_teacher=0.544, kd_loss=3.252, ppl=1.98, wps=34083.8, ups=0.74, wpb=46358.8, bsz=3125.9, num_updates=212100, lr=6.86641e-05, gnorm=0.291, clip=0, loss_scale=8, train_wall=136, gb_free=20.9, wall=5709
2022-11-02 06:21:56 | INFO | train_inner | epoch 014:   3883 / 16028 loss=2.965, nll_loss=1, nll_loss_teacher=0.545, kd_loss=3.261, ppl=2, wps=33303.4, ups=0.73, wpb=45705.5, bsz=2956.6, num_updates=212200, lr=6.86479e-05, gnorm=0.306, clip=0, loss_scale=8, train_wall=137, gb_free=23.1, wall=5846
2022-11-02 06:24:14 | INFO | train_inner | epoch 014:   3983 / 16028 loss=2.953, nll_loss=0.993, nll_loss_teacher=0.542, kd_loss=3.245, ppl=1.99, wps=32684.9, ups=0.72, wpb=45172.8, bsz=3212.2, num_updates=212300, lr=6.86317e-05, gnorm=0.304, clip=0, loss_scale=8, train_wall=138, gb_free=20.2, wall=5984
2022-11-02 06:26:33 | INFO | train_inner | epoch 014:   4083 / 16028 loss=2.95, nll_loss=0.989, nll_loss_teacher=0.541, kd_loss=3.241, ppl=1.99, wps=33476.9, ups=0.72, wpb=46320.8, bsz=3294.7, num_updates=212400, lr=6.86156e-05, gnorm=0.292, clip=0, loss_scale=8, train_wall=138, gb_free=26.8, wall=6122
2022-11-02 06:28:50 | INFO | train_inner | epoch 014:   4183 / 16028 loss=2.954, nll_loss=0.991, nll_loss_teacher=0.54, kd_loss=3.245, ppl=1.99, wps=33638.2, ups=0.73, wpb=46032.7, bsz=2915.2, num_updates=212500, lr=6.85994e-05, gnorm=0.294, clip=0, loss_scale=8, train_wall=137, gb_free=23.3, wall=6259
2022-11-02 06:31:07 | INFO | train_inner | epoch 014:   4283 / 16028 loss=2.957, nll_loss=0.992, nll_loss_teacher=0.544, kd_loss=3.254, ppl=1.99, wps=32821.4, ups=0.73, wpb=45104.1, bsz=3145.8, num_updates=212600, lr=6.85833e-05, gnorm=0.301, clip=0, loss_scale=8, train_wall=137, gb_free=26.4, wall=6397
2022-11-02 06:33:25 | INFO | train_inner | epoch 014:   4383 / 16028 loss=2.962, nll_loss=1, nll_loss_teacher=0.542, kd_loss=3.254, ppl=2, wps=32757.4, ups=0.73, wpb=45104.5, bsz=3011.4, num_updates=212700, lr=6.85672e-05, gnorm=0.296, clip=0, loss_scale=8, train_wall=138, gb_free=23.3, wall=6534
2022-11-02 06:35:40 | INFO | train_inner | epoch 014:   4483 / 16028 loss=2.959, nll_loss=0.999, nll_loss_teacher=0.54, kd_loss=3.247, ppl=2, wps=33878.9, ups=0.74, wpb=45725.5, bsz=3088.3, num_updates=212800, lr=6.85511e-05, gnorm=0.297, clip=0, loss_scale=8, train_wall=135, gb_free=19, wall=6669
2022-11-02 06:37:58 | INFO | train_inner | epoch 014:   4583 / 16028 loss=2.953, nll_loss=0.991, nll_loss_teacher=0.541, kd_loss=3.247, ppl=1.99, wps=33550.6, ups=0.72, wpb=46373.6, bsz=3062, num_updates=212900, lr=6.8535e-05, gnorm=0.3, clip=0, loss_scale=8, train_wall=138, gb_free=21.7, wall=6808
2022-11-02 06:40:16 | INFO | train_inner | epoch 014:   4683 / 16028 loss=2.961, nll_loss=0.998, nll_loss_teacher=0.544, kd_loss=3.257, ppl=2, wps=33287.3, ups=0.73, wpb=45849.6, bsz=3194.1, num_updates=213000, lr=6.85189e-05, gnorm=0.301, clip=0, loss_scale=8, train_wall=138, gb_free=19.2, wall=6945
2022-11-02 06:42:33 | INFO | train_inner | epoch 014:   4783 / 16028 loss=2.948, nll_loss=0.987, nll_loss_teacher=0.539, kd_loss=3.235, ppl=1.98, wps=33592.4, ups=0.73, wpb=46068.6, bsz=3129.4, num_updates=213100, lr=6.85028e-05, gnorm=0.288, clip=0, loss_scale=8, train_wall=137, gb_free=21.7, wall=7082
2022-11-02 06:44:50 | INFO | train_inner | epoch 014:   4883 / 16028 loss=2.956, nll_loss=0.996, nll_loss_teacher=0.539, kd_loss=3.245, ppl=1.99, wps=33736.7, ups=0.73, wpb=46223.1, bsz=3074, num_updates=213200, lr=6.84867e-05, gnorm=0.299, clip=0, loss_scale=8, train_wall=137, gb_free=21.6, wall=7219
2022-11-02 06:47:04 | INFO | train_inner | epoch 014:   4983 / 16028 loss=2.957, nll_loss=0.995, nll_loss_teacher=0.541, kd_loss=3.246, ppl=1.99, wps=34644.2, ups=0.75, wpb=46474.9, bsz=3053.9, num_updates=213300, lr=6.84707e-05, gnorm=0.3, clip=0, loss_scale=8, train_wall=134, gb_free=23.2, wall=7354
2022-11-02 06:49:18 | INFO | train_inner | epoch 014:   5083 / 16028 loss=2.963, nll_loss=1, nll_loss_teacher=0.543, kd_loss=3.259, ppl=2, wps=34351.6, ups=0.75, wpb=45889.2, bsz=2933.2, num_updates=213400, lr=6.84546e-05, gnorm=0.3, clip=0, loss_scale=8, train_wall=133, gb_free=24.2, wall=7487
2022-11-02 06:51:34 | INFO | train_inner | epoch 014:   5183 / 16028 loss=2.952, nll_loss=0.989, nll_loss_teacher=0.543, kd_loss=3.25, ppl=1.99, wps=33219.7, ups=0.73, wpb=45454.3, bsz=3105.5, num_updates=213500, lr=6.84386e-05, gnorm=0.293, clip=0, loss_scale=8, train_wall=137, gb_free=22.6, wall=7624
2022-11-02 06:53:51 | INFO | train_inner | epoch 014:   5283 / 16028 loss=2.956, nll_loss=0.994, nll_loss_teacher=0.542, kd_loss=3.252, ppl=1.99, wps=33205.2, ups=0.73, wpb=45302.3, bsz=3066.6, num_updates=213600, lr=6.84226e-05, gnorm=0.295, clip=0, loss_scale=8, train_wall=136, gb_free=22.1, wall=7760
2022-11-02 06:56:07 | INFO | train_inner | epoch 014:   5383 / 16028 loss=2.956, nll_loss=0.996, nll_loss_teacher=0.541, kd_loss=3.247, ppl=1.99, wps=33300.7, ups=0.74, wpb=45273.8, bsz=3168.3, num_updates=213700, lr=6.84066e-05, gnorm=0.303, clip=0, loss_scale=8, train_wall=136, gb_free=24.6, wall=7896
2022-11-02 06:58:19 | INFO | train_inner | epoch 014:   5483 / 16028 loss=2.957, nll_loss=0.996, nll_loss_teacher=0.541, kd_loss=3.25, ppl=2, wps=34922.9, ups=0.76, wpb=46111.3, bsz=3156.8, num_updates=213800, lr=6.83906e-05, gnorm=0.305, clip=0, loss_scale=8, train_wall=132, gb_free=24.8, wall=8028
2022-11-02 07:00:32 | INFO | train_inner | epoch 014:   5583 / 16028 loss=2.954, nll_loss=0.992, nll_loss_teacher=0.541, kd_loss=3.247, ppl=1.99, wps=35383.1, ups=0.75, wpb=47102.5, bsz=3104.3, num_updates=213900, lr=6.83746e-05, gnorm=0.292, clip=0, loss_scale=8, train_wall=133, gb_free=18.4, wall=8162
2022-11-02 07:02:48 | INFO | train_inner | epoch 014:   5683 / 16028 loss=2.962, nll_loss=0.999, nll_loss_teacher=0.543, kd_loss=3.258, ppl=2, wps=32961.9, ups=0.73, wpb=44963.5, bsz=3111, num_updates=214000, lr=6.83586e-05, gnorm=0.308, clip=0, loss_scale=8, train_wall=136, gb_free=20.3, wall=8298
2022-11-02 07:05:05 | INFO | train_inner | epoch 014:   5783 / 16028 loss=2.945, nll_loss=0.986, nll_loss_teacher=0.538, kd_loss=3.233, ppl=1.98, wps=33636.2, ups=0.73, wpb=46057.8, bsz=3246.8, num_updates=214100, lr=6.83426e-05, gnorm=0.295, clip=0, loss_scale=8, train_wall=137, gb_free=21, wall=8435
2022-11-02 07:07:21 | INFO | train_inner | epoch 014:   5883 / 16028 loss=2.962, nll_loss=0.998, nll_loss_teacher=0.545, kd_loss=3.254, ppl=2, wps=33885.9, ups=0.74, wpb=45938, bsz=3041.7, num_updates=214200, lr=6.83267e-05, gnorm=0.3, clip=0, loss_scale=8, train_wall=135, gb_free=22.3, wall=8570
2022-11-02 07:09:38 | INFO | train_inner | epoch 014:   5983 / 16028 loss=2.957, nll_loss=0.994, nll_loss_teacher=0.542, kd_loss=3.25, ppl=1.99, wps=33944.5, ups=0.73, wpb=46523.4, bsz=2990.4, num_updates=214300, lr=6.83107e-05, gnorm=0.291, clip=0, loss_scale=8, train_wall=137, gb_free=21.2, wall=8708
2022-11-02 07:11:55 | INFO | train_inner | epoch 014:   6083 / 16028 loss=2.956, nll_loss=0.993, nll_loss_teacher=0.544, kd_loss=3.256, ppl=1.99, wps=33462.6, ups=0.73, wpb=45876.6, bsz=3041.5, num_updates=214400, lr=6.82948e-05, gnorm=0.291, clip=0, loss_scale=8, train_wall=137, gb_free=16.5, wall=8845
2022-11-02 07:14:13 | INFO | train_inner | epoch 014:   6183 / 16028 loss=2.958, nll_loss=0.995, nll_loss_teacher=0.544, kd_loss=3.258, ppl=1.99, wps=32903.8, ups=0.73, wpb=45319.7, bsz=3106.3, num_updates=214500, lr=6.82789e-05, gnorm=0.301, clip=0, loss_scale=8, train_wall=137, gb_free=26.7, wall=8982
2022-11-02 07:16:29 | INFO | train_inner | epoch 014:   6283 / 16028 loss=2.966, nll_loss=1.004, nll_loss_teacher=0.544, kd_loss=3.262, ppl=2, wps=33543.4, ups=0.74, wpb=45609.2, bsz=3035.8, num_updates=214600, lr=6.8263e-05, gnorm=0.305, clip=0, loss_scale=16, train_wall=136, gb_free=22.7, wall=9118
2022-11-02 07:18:45 | INFO | train_inner | epoch 014:   6383 / 16028 loss=2.95, nll_loss=0.989, nll_loss_teacher=0.542, kd_loss=3.247, ppl=1.98, wps=33352.5, ups=0.73, wpb=45616, bsz=3269, num_updates=214700, lr=6.82471e-05, gnorm=0.295, clip=0, loss_scale=16, train_wall=137, gb_free=21.5, wall=9255
2022-11-02 07:21:03 | INFO | train_inner | epoch 014:   6483 / 16028 loss=2.958, nll_loss=0.992, nll_loss_teacher=0.545, kd_loss=3.256, ppl=1.99, wps=33304.1, ups=0.73, wpb=45706.7, bsz=2969.9, num_updates=214800, lr=6.82312e-05, gnorm=0.304, clip=0, loss_scale=16, train_wall=137, gb_free=22.1, wall=9392
2022-11-02 07:23:19 | INFO | train_inner | epoch 014:   6583 / 16028 loss=2.97, nll_loss=1.007, nll_loss_teacher=0.544, kd_loss=3.263, ppl=2.01, wps=33843.1, ups=0.74, wpb=45989.7, bsz=2863.4, num_updates=214900, lr=6.82153e-05, gnorm=0.31, clip=0, loss_scale=16, train_wall=136, gb_free=19.4, wall=9528
2022-11-02 07:24:22 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-11-02 07:25:36 | INFO | train_inner | epoch 014:   6684 / 16028 loss=2.957, nll_loss=0.994, nll_loss_teacher=0.549, kd_loss=3.258, ppl=1.99, wps=33407.5, ups=0.73, wpb=45883.3, bsz=3241.4, num_updates=215000, lr=6.81994e-05, gnorm=0.3, clip=0, loss_scale=8, train_wall=137, gb_free=24.2, wall=9666
2022-11-02 07:27:49 | INFO | train_inner | epoch 014:   6784 / 16028 loss=2.963, nll_loss=1, nll_loss_teacher=0.544, kd_loss=3.261, ppl=2, wps=34479.8, ups=0.75, wpb=45878.9, bsz=3000.7, num_updates=215100, lr=6.81836e-05, gnorm=0.32, clip=0, loss_scale=8, train_wall=133, gb_free=17.1, wall=9799
2022-11-02 07:30:06 | INFO | train_inner | epoch 014:   6884 / 16028 loss=2.958, nll_loss=0.996, nll_loss_teacher=0.543, kd_loss=3.253, ppl=1.99, wps=33317.8, ups=0.73, wpb=45492.5, bsz=3033.5, num_updates=215200, lr=6.81677e-05, gnorm=0.3, clip=0, loss_scale=8, train_wall=136, gb_free=17.5, wall=9935
2022-11-02 07:32:21 | INFO | train_inner | epoch 014:   6984 / 16028 loss=2.965, nll_loss=1.002, nll_loss_teacher=0.543, kd_loss=3.254, ppl=2, wps=33186.7, ups=0.74, wpb=44971, bsz=3086.5, num_updates=215300, lr=6.81519e-05, gnorm=0.324, clip=0, loss_scale=8, train_wall=135, gb_free=18.4, wall=10071
2022-11-02 07:34:38 | INFO | train_inner | epoch 014:   7084 / 16028 loss=2.968, nll_loss=1.006, nll_loss_teacher=0.545, kd_loss=3.265, ppl=2.01, wps=33459.2, ups=0.73, wpb=45804.4, bsz=3104.9, num_updates=215400, lr=6.81361e-05, gnorm=0.317, clip=0, loss_scale=8, train_wall=137, gb_free=19.2, wall=10208
2022-11-02 07:36:55 | INFO | train_inner | epoch 014:   7184 / 16028 loss=2.955, nll_loss=0.992, nll_loss_teacher=0.542, kd_loss=3.251, ppl=1.99, wps=33344.2, ups=0.73, wpb=45606.2, bsz=3168.9, num_updates=215500, lr=6.81203e-05, gnorm=0.305, clip=0, loss_scale=8, train_wall=137, gb_free=22.8, wall=10344
2022-11-02 07:39:11 | INFO | train_inner | epoch 014:   7284 / 16028 loss=2.957, nll_loss=0.998, nll_loss_teacher=0.541, kd_loss=3.248, ppl=2, wps=32748.4, ups=0.73, wpb=44752.1, bsz=3163.4, num_updates=215600, lr=6.81045e-05, gnorm=0.292, clip=0, loss_scale=8, train_wall=136, gb_free=21.3, wall=10481
2022-11-02 07:41:25 | INFO | train_inner | epoch 014:   7384 / 16028 loss=2.953, nll_loss=0.992, nll_loss_teacher=0.541, kd_loss=3.244, ppl=1.99, wps=35258.6, ups=0.75, wpb=46986.8, bsz=3115.8, num_updates=215700, lr=6.80887e-05, gnorm=0.301, clip=0, loss_scale=8, train_wall=133, gb_free=19.6, wall=10614
2022-11-02 07:43:41 | INFO | train_inner | epoch 014:   7484 / 16028 loss=2.955, nll_loss=0.994, nll_loss_teacher=0.543, kd_loss=3.251, ppl=1.99, wps=33777.2, ups=0.74, wpb=45904, bsz=3135.7, num_updates=215800, lr=6.80729e-05, gnorm=0.296, clip=0, loss_scale=8, train_wall=136, gb_free=23.8, wall=10750
2022-11-02 07:45:55 | INFO | train_inner | epoch 014:   7584 / 16028 loss=2.957, nll_loss=0.997, nll_loss_teacher=0.543, kd_loss=3.252, ppl=2, wps=33892.7, ups=0.74, wpb=45717.6, bsz=3224.3, num_updates=215900, lr=6.80571e-05, gnorm=0.314, clip=0, loss_scale=8, train_wall=135, gb_free=20.4, wall=10885
2022-11-02 07:48:12 | INFO | train_inner | epoch 014:   7684 / 16028 loss=2.963, nll_loss=1.002, nll_loss_teacher=0.541, kd_loss=3.249, ppl=2, wps=33811.9, ups=0.73, wpb=46072.3, bsz=3047, num_updates=216000, lr=6.80414e-05, gnorm=0.305, clip=0, loss_scale=8, train_wall=136, gb_free=16.8, wall=11021
2022-11-02 07:50:29 | INFO | train_inner | epoch 014:   7784 / 16028 loss=2.957, nll_loss=0.994, nll_loss_teacher=0.543, kd_loss=3.253, ppl=1.99, wps=33172.7, ups=0.73, wpb=45368.3, bsz=3072.2, num_updates=216100, lr=6.80256e-05, gnorm=0.29, clip=0, loss_scale=8, train_wall=137, gb_free=26, wall=11158
2022-11-02 07:52:44 | INFO | train_inner | epoch 014:   7884 / 16028 loss=2.959, nll_loss=0.996, nll_loss_teacher=0.543, kd_loss=3.254, ppl=1.99, wps=34187.4, ups=0.74, wpb=46330, bsz=3075.4, num_updates=216200, lr=6.80099e-05, gnorm=0.287, clip=0, loss_scale=8, train_wall=135, gb_free=21.4, wall=11294
2022-11-02 07:54:59 | INFO | train_inner | epoch 014:   7984 / 16028 loss=2.967, nll_loss=1.002, nll_loss_teacher=0.548, kd_loss=3.269, ppl=2, wps=33576.5, ups=0.74, wpb=45188.7, bsz=3075.6, num_updates=216300, lr=6.79942e-05, gnorm=0.318, clip=0, loss_scale=8, train_wall=134, gb_free=19.9, wall=11428
2022-11-02 07:57:15 | INFO | train_inner | epoch 014:   8084 / 16028 loss=2.964, nll_loss=1, nll_loss_teacher=0.548, kd_loss=3.265, ppl=2, wps=33554.3, ups=0.73, wpb=45780.3, bsz=3037, num_updates=216400, lr=6.79785e-05, gnorm=0.298, clip=0, loss_scale=8, train_wall=136, gb_free=17.5, wall=11565
2022-11-02 07:59:30 | INFO | train_inner | epoch 014:   8184 / 16028 loss=2.962, nll_loss=1.001, nll_loss_teacher=0.541, kd_loss=3.253, ppl=2, wps=34090, ups=0.74, wpb=45977.2, bsz=2891.7, num_updates=216500, lr=6.79628e-05, gnorm=0.301, clip=0, loss_scale=8, train_wall=135, gb_free=24.3, wall=11700
2022-11-02 08:01:46 | INFO | train_inner | epoch 014:   8284 / 16028 loss=2.953, nll_loss=0.992, nll_loss_teacher=0.54, kd_loss=3.247, ppl=1.99, wps=33424.3, ups=0.73, wpb=45643.7, bsz=3117.3, num_updates=216600, lr=6.79471e-05, gnorm=0.291, clip=0, loss_scale=8, train_wall=136, gb_free=26.1, wall=11836
2022-11-02 08:04:02 | INFO | train_inner | epoch 014:   8384 / 16028 loss=2.949, nll_loss=0.987, nll_loss_teacher=0.541, kd_loss=3.245, ppl=1.98, wps=34660.1, ups=0.74, wpb=46834.9, bsz=3119, num_updates=216700, lr=6.79314e-05, gnorm=0.289, clip=0, loss_scale=8, train_wall=135, gb_free=26.6, wall=11971
2022-11-02 08:06:18 | INFO | train_inner | epoch 014:   8484 / 16028 loss=2.963, nll_loss=0.999, nll_loss_teacher=0.544, kd_loss=3.257, ppl=2, wps=33506.4, ups=0.73, wpb=45830.4, bsz=3020.5, num_updates=216800, lr=6.79157e-05, gnorm=0.309, clip=0, loss_scale=8, train_wall=137, gb_free=23.8, wall=12108
2022-11-02 08:08:36 | INFO | train_inner | epoch 014:   8584 / 16028 loss=2.949, nll_loss=0.989, nll_loss_teacher=0.542, kd_loss=3.246, ppl=1.98, wps=33991.8, ups=0.73, wpb=46694.8, bsz=3256.4, num_updates=216900, lr=6.79001e-05, gnorm=0.289, clip=0, loss_scale=8, train_wall=137, gb_free=20.6, wall=12245
2022-11-02 08:10:54 | INFO | train_inner | epoch 014:   8684 / 16028 loss=2.96, nll_loss=0.998, nll_loss_teacher=0.543, kd_loss=3.257, ppl=2, wps=32888.3, ups=0.72, wpb=45372.7, bsz=3165.8, num_updates=217000, lr=6.78844e-05, gnorm=0.303, clip=0, loss_scale=8, train_wall=138, gb_free=23.8, wall=12383
2022-11-02 08:13:11 | INFO | train_inner | epoch 014:   8784 / 16028 loss=2.957, nll_loss=0.997, nll_loss_teacher=0.541, kd_loss=3.248, ppl=2, wps=33532.3, ups=0.73, wpb=45958.9, bsz=3114, num_updates=217100, lr=6.78688e-05, gnorm=0.3, clip=0, loss_scale=8, train_wall=137, gb_free=21.4, wall=12520
2022-11-02 08:15:27 | INFO | train_inner | epoch 014:   8884 / 16028 loss=2.956, nll_loss=0.994, nll_loss_teacher=0.541, kd_loss=3.25, ppl=1.99, wps=33665, ups=0.73, wpb=46007.8, bsz=3073.8, num_updates=217200, lr=6.78532e-05, gnorm=0.3, clip=0, loss_scale=8, train_wall=136, gb_free=25.6, wall=12657
2022-11-02 08:17:44 | INFO | train_inner | epoch 014:   8984 / 16028 loss=2.965, nll_loss=1.004, nll_loss_teacher=0.541, kd_loss=3.25, ppl=2.01, wps=33501.3, ups=0.73, wpb=45795.8, bsz=2811, num_updates=217300, lr=6.78375e-05, gnorm=0.3, clip=0, loss_scale=8, train_wall=137, gb_free=20, wall=12794
2022-11-02 08:20:01 | INFO | train_inner | epoch 014:   9084 / 16028 loss=2.965, nll_loss=1.002, nll_loss_teacher=0.544, kd_loss=3.259, ppl=2, wps=32731.2, ups=0.73, wpb=44774.7, bsz=2958.6, num_updates=217400, lr=6.78219e-05, gnorm=0.307, clip=0, loss_scale=8, train_wall=137, gb_free=20.4, wall=12931
2022-11-02 08:22:17 | INFO | train_inner | epoch 014:   9184 / 16028 loss=2.957, nll_loss=0.996, nll_loss_teacher=0.541, kd_loss=3.249, ppl=1.99, wps=33864.7, ups=0.73, wpb=46181.7, bsz=3086.2, num_updates=217500, lr=6.78064e-05, gnorm=0.304, clip=0, loss_scale=8, train_wall=136, gb_free=30.3, wall=13067
2022-11-02 08:24:34 | INFO | train_inner | epoch 014:   9284 / 16028 loss=2.96, nll_loss=0.999, nll_loss_teacher=0.54, kd_loss=3.25, ppl=2, wps=33369.6, ups=0.73, wpb=45726.4, bsz=3047, num_updates=217600, lr=6.77908e-05, gnorm=0.299, clip=0, loss_scale=8, train_wall=137, gb_free=20.9, wall=13204
2022-11-02 08:26:52 | INFO | train_inner | epoch 014:   9384 / 16028 loss=2.954, nll_loss=0.992, nll_loss_teacher=0.541, kd_loss=3.246, ppl=1.99, wps=32947.5, ups=0.73, wpb=45331.8, bsz=3097.8, num_updates=217700, lr=6.77752e-05, gnorm=0.293, clip=0, loss_scale=8, train_wall=137, gb_free=22.6, wall=13342
2022-11-02 08:29:08 | INFO | train_inner | epoch 014:   9484 / 16028 loss=2.949, nll_loss=0.99, nll_loss_teacher=0.54, kd_loss=3.239, ppl=1.99, wps=33723.4, ups=0.73, wpb=46043.1, bsz=3147.4, num_updates=217800, lr=6.77596e-05, gnorm=0.296, clip=0, loss_scale=8, train_wall=136, gb_free=21, wall=13478
2022-11-02 08:31:24 | INFO | train_inner | epoch 014:   9584 / 16028 loss=2.959, nll_loss=0.998, nll_loss_teacher=0.544, kd_loss=3.258, ppl=2, wps=33793.5, ups=0.74, wpb=45895.3, bsz=3119.3, num_updates=217900, lr=6.77441e-05, gnorm=0.298, clip=0, loss_scale=8, train_wall=136, gb_free=24.3, wall=13614
2022-11-02 08:33:39 | INFO | train_inner | epoch 014:   9684 / 16028 loss=2.959, nll_loss=0.998, nll_loss_teacher=0.544, kd_loss=3.257, ppl=2, wps=34133.9, ups=0.74, wpb=46031.6, bsz=3172.9, num_updates=218000, lr=6.77285e-05, gnorm=0.296, clip=0, loss_scale=8, train_wall=135, gb_free=22.9, wall=13749
2022-11-02 08:35:53 | INFO | train_inner | epoch 014:   9784 / 16028 loss=2.957, nll_loss=0.995, nll_loss_teacher=0.544, kd_loss=3.254, ppl=1.99, wps=34373.5, ups=0.75, wpb=45908, bsz=3141.1, num_updates=218100, lr=6.7713e-05, gnorm=0.285, clip=0, loss_scale=8, train_wall=133, gb_free=21.9, wall=13882
2022-11-02 08:38:09 | INFO | train_inner | epoch 014:   9884 / 16028 loss=2.955, nll_loss=0.993, nll_loss_teacher=0.544, kd_loss=3.255, ppl=1.99, wps=33574.5, ups=0.73, wpb=45877.1, bsz=3075, num_updates=218200, lr=6.76975e-05, gnorm=0.297, clip=0, loss_scale=8, train_wall=136, gb_free=23.6, wall=14019
2022-11-02 08:40:26 | INFO | train_inner | epoch 014:   9984 / 16028 loss=2.959, nll_loss=1, nll_loss_teacher=0.539, kd_loss=3.245, ppl=2, wps=33347.5, ups=0.73, wpb=45469.1, bsz=3135.2, num_updates=218300, lr=6.7682e-05, gnorm=0.3, clip=0, loss_scale=8, train_wall=136, gb_free=23.2, wall=14155
2022-11-02 08:42:43 | INFO | train_inner | epoch 014:  10084 / 16028 loss=2.949, nll_loss=0.99, nll_loss_teacher=0.54, kd_loss=3.242, ppl=1.99, wps=33443.4, ups=0.73, wpb=45969.6, bsz=3270.6, num_updates=218400, lr=6.76665e-05, gnorm=0.293, clip=0, loss_scale=8, train_wall=137, gb_free=18, wall=14293
2022-11-02 08:44:57 | INFO | train_inner | epoch 014:  10184 / 16028 loss=2.952, nll_loss=0.992, nll_loss_teacher=0.542, kd_loss=3.245, ppl=1.99, wps=34565, ups=0.75, wpb=46338.7, bsz=3213.9, num_updates=218500, lr=6.7651e-05, gnorm=0.294, clip=0, loss_scale=8, train_wall=134, gb_free=21.1, wall=14427
2022-11-02 08:47:13 | INFO | train_inner | epoch 014:  10284 / 16028 loss=2.95, nll_loss=0.989, nll_loss_teacher=0.542, kd_loss=3.246, ppl=1.99, wps=33741.3, ups=0.74, wpb=45847, bsz=3256, num_updates=218600, lr=6.76355e-05, gnorm=0.3, clip=0, loss_scale=8, train_wall=136, gb_free=19.8, wall=14563
2022-11-02 08:49:29 | INFO | train_inner | epoch 014:  10384 / 16028 loss=2.943, nll_loss=0.981, nll_loss_teacher=0.539, kd_loss=3.235, ppl=1.97, wps=34127.5, ups=0.74, wpb=46303.6, bsz=3251.5, num_updates=218700, lr=6.76201e-05, gnorm=0.294, clip=0, loss_scale=8, train_wall=135, gb_free=22, wall=14698
2022-11-02 08:51:45 | INFO | train_inner | epoch 014:  10484 / 16028 loss=2.956, nll_loss=0.993, nll_loss_teacher=0.543, kd_loss=3.247, ppl=1.99, wps=32967.6, ups=0.73, wpb=44945.7, bsz=3076.5, num_updates=218800, lr=6.76046e-05, gnorm=0.305, clip=0, loss_scale=8, train_wall=136, gb_free=19.8, wall=14835
2022-11-02 08:54:01 | INFO | train_inner | epoch 014:  10584 / 16028 loss=2.958, nll_loss=0.995, nll_loss_teacher=0.544, kd_loss=3.254, ppl=1.99, wps=33380.6, ups=0.74, wpb=45235.3, bsz=3092.8, num_updates=218900, lr=6.75892e-05, gnorm=0.305, clip=0, loss_scale=8, train_wall=135, gb_free=20.6, wall=14970
2022-11-02 08:56:15 | INFO | train_inner | epoch 014:  10684 / 16028 loss=2.96, nll_loss=0.998, nll_loss_teacher=0.545, kd_loss=3.262, ppl=2, wps=33853.7, ups=0.75, wpb=45318.7, bsz=3316.3, num_updates=219000, lr=6.75737e-05, gnorm=0.307, clip=0, loss_scale=8, train_wall=134, gb_free=23.1, wall=15104
2022-11-02 08:58:31 | INFO | train_inner | epoch 014:  10784 / 16028 loss=2.955, nll_loss=0.993, nll_loss_teacher=0.542, kd_loss=3.251, ppl=1.99, wps=33293.5, ups=0.73, wpb=45535.4, bsz=3043, num_updates=219100, lr=6.75583e-05, gnorm=0.295, clip=0, loss_scale=16, train_wall=137, gb_free=22.3, wall=15241
2022-11-02 09:00:48 | INFO | train_inner | epoch 014:  10884 / 16028 loss=2.956, nll_loss=0.994, nll_loss_teacher=0.542, kd_loss=3.247, ppl=1.99, wps=33269.2, ups=0.73, wpb=45649.4, bsz=2997.4, num_updates=219200, lr=6.75429e-05, gnorm=0.298, clip=0, loss_scale=16, train_wall=137, gb_free=24.9, wall=15378
2022-11-02 09:03:04 | INFO | train_inner | epoch 014:  10984 / 16028 loss=2.964, nll_loss=1.002, nll_loss_teacher=0.545, kd_loss=3.256, ppl=2, wps=34309.5, ups=0.74, wpb=46591.2, bsz=2984.6, num_updates=219300, lr=6.75275e-05, gnorm=0.301, clip=0, loss_scale=16, train_wall=136, gb_free=17, wall=15514
2022-11-02 09:05:20 | INFO | train_inner | epoch 014:  11084 / 16028 loss=2.952, nll_loss=0.99, nll_loss_teacher=0.542, kd_loss=3.246, ppl=1.99, wps=34286.4, ups=0.74, wpb=46390.8, bsz=3054.6, num_updates=219400, lr=6.75121e-05, gnorm=0.293, clip=0, loss_scale=16, train_wall=135, gb_free=25.1, wall=15649
2022-11-02 09:07:31 | INFO | train_inner | epoch 014:  11184 / 16028 loss=2.953, nll_loss=0.992, nll_loss_teacher=0.542, kd_loss=3.25, ppl=1.99, wps=34991.1, ups=0.76, wpb=45994.7, bsz=3196.7, num_updates=219500, lr=6.74967e-05, gnorm=0.29, clip=0, loss_scale=16, train_wall=131, gb_free=22.1, wall=15781
2022-11-02 09:09:48 | INFO | train_inner | epoch 014:  11284 / 16028 loss=2.956, nll_loss=0.994, nll_loss_teacher=0.543, kd_loss=3.252, ppl=1.99, wps=33980.4, ups=0.73, wpb=46568, bsz=3117.5, num_updates=219600, lr=6.74814e-05, gnorm=0.296, clip=0, loss_scale=16, train_wall=137, gb_free=17.8, wall=15918
2022-11-02 09:12:05 | INFO | train_inner | epoch 014:  11384 / 16028 loss=2.963, nll_loss=1.001, nll_loss_teacher=0.545, kd_loss=3.258, ppl=2, wps=33912.6, ups=0.73, wpb=46551.8, bsz=3064, num_updates=219700, lr=6.7466e-05, gnorm=0.31, clip=0, loss_scale=16, train_wall=137, gb_free=24.2, wall=16055
2022-11-02 09:14:21 | INFO | train_inner | epoch 014:  11484 / 16028 loss=2.952, nll_loss=0.992, nll_loss_teacher=0.541, kd_loss=3.244, ppl=1.99, wps=33619.3, ups=0.74, wpb=45679, bsz=3252, num_updates=219800, lr=6.74507e-05, gnorm=0.296, clip=0, loss_scale=16, train_wall=136, gb_free=17.8, wall=16191
2022-11-02 09:16:38 | INFO | train_inner | epoch 014:  11584 / 16028 loss=2.956, nll_loss=0.998, nll_loss_teacher=0.539, kd_loss=3.241, ppl=2, wps=33472.7, ups=0.73, wpb=45733.8, bsz=3097.8, num_updates=219900, lr=6.74353e-05, gnorm=0.307, clip=0, loss_scale=16, train_wall=136, gb_free=25.5, wall=16327
2022-11-02 09:18:53 | INFO | train_inner | epoch 014:  11684 / 16028 loss=2.961, nll_loss=1.001, nll_loss_teacher=0.541, kd_loss=3.249, ppl=2, wps=33433.2, ups=0.74, wpb=45170.4, bsz=3154, num_updates=220000, lr=6.742e-05, gnorm=0.307, clip=0, loss_scale=16, train_wall=135, gb_free=24.3, wall=16463
2022-11-02 09:21:09 | INFO | train_inner | epoch 014:  11784 / 16028 loss=2.958, nll_loss=0.996, nll_loss_teacher=0.545, kd_loss=3.256, ppl=1.99, wps=33206.2, ups=0.73, wpb=45211.2, bsz=3227.9, num_updates=220100, lr=6.74047e-05, gnorm=0.309, clip=0, loss_scale=16, train_wall=136, gb_free=18.6, wall=16599
2022-11-02 09:23:23 | INFO | train_inner | epoch 014:  11884 / 16028 loss=2.953, nll_loss=0.992, nll_loss_teacher=0.544, kd_loss=3.249, ppl=1.99, wps=34653.1, ups=0.75, wpb=46445.1, bsz=3296.2, num_updates=220200, lr=6.73894e-05, gnorm=0.291, clip=0, loss_scale=16, train_wall=134, gb_free=21, wall=16733
2022-11-02 09:25:41 | INFO | train_inner | epoch 014:  11984 / 16028 loss=2.958, nll_loss=0.999, nll_loss_teacher=0.543, kd_loss=3.243, ppl=2, wps=33249.5, ups=0.73, wpb=45797.8, bsz=3122.2, num_updates=220300, lr=6.73741e-05, gnorm=0.301, clip=0, loss_scale=16, train_wall=138, gb_free=24.5, wall=16871
2022-11-02 09:27:59 | INFO | train_inner | epoch 014:  12084 / 16028 loss=2.963, nll_loss=1.002, nll_loss_teacher=0.544, kd_loss=3.254, ppl=2, wps=33414.9, ups=0.73, wpb=45982.6, bsz=2977.8, num_updates=220400, lr=6.73588e-05, gnorm=0.303, clip=0, loss_scale=16, train_wall=137, gb_free=20.6, wall=17008
2022-11-02 09:30:14 | INFO | train_inner | epoch 014:  12184 / 16028 loss=2.955, nll_loss=0.993, nll_loss_teacher=0.544, kd_loss=3.255, ppl=1.99, wps=34078, ups=0.74, wpb=46084.5, bsz=3186, num_updates=220500, lr=6.73435e-05, gnorm=0.303, clip=0, loss_scale=16, train_wall=135, gb_free=22.8, wall=17143
2022-11-02 09:32:31 | INFO | train_inner | epoch 014:  12284 / 16028 loss=2.949, nll_loss=0.989, nll_loss_teacher=0.539, kd_loss=3.234, ppl=1.98, wps=33696.6, ups=0.73, wpb=46196.5, bsz=3136.3, num_updates=220600, lr=6.73282e-05, gnorm=0.303, clip=0, loss_scale=16, train_wall=137, gb_free=17.5, wall=17280
2022-11-02 09:34:48 | INFO | train_inner | epoch 014:  12384 / 16028 loss=2.949, nll_loss=0.989, nll_loss_teacher=0.542, kd_loss=3.246, ppl=1.99, wps=33549, ups=0.73, wpb=45962.6, bsz=3198.6, num_updates=220700, lr=6.7313e-05, gnorm=0.292, clip=0, loss_scale=16, train_wall=137, gb_free=27.7, wall=17417
2022-11-02 09:37:03 | INFO | train_inner | epoch 014:  12484 / 16028 loss=2.957, nll_loss=0.997, nll_loss_teacher=0.545, kd_loss=3.253, ppl=2, wps=33968.4, ups=0.74, wpb=45957.2, bsz=3065.8, num_updates=220800, lr=6.72977e-05, gnorm=0.312, clip=0, loss_scale=16, train_wall=135, gb_free=18, wall=17553
2022-11-02 09:39:24 | INFO | train_inner | epoch 014:  12584 / 16028 loss=2.968, nll_loss=1.006, nll_loss_teacher=0.544, kd_loss=3.259, ppl=2.01, wps=33124.1, ups=0.71, wpb=46562.9, bsz=3059, num_updates=220900, lr=6.72825e-05, gnorm=0.319, clip=1, loss_scale=16, train_wall=140, gb_free=22, wall=17693
2022-11-02 09:41:41 | INFO | train_inner | epoch 014:  12684 / 16028 loss=2.946, nll_loss=0.985, nll_loss_teacher=0.541, kd_loss=3.24, ppl=1.98, wps=33516.2, ups=0.73, wpb=45891.7, bsz=3210.6, num_updates=221000, lr=6.72673e-05, gnorm=0.287, clip=0, loss_scale=16, train_wall=137, gb_free=19.6, wall=17830
2022-11-02 09:43:58 | INFO | train_inner | epoch 014:  12784 / 16028 loss=2.954, nll_loss=0.993, nll_loss_teacher=0.542, kd_loss=3.247, ppl=1.99, wps=33286.3, ups=0.73, wpb=45704.1, bsz=3088.4, num_updates=221100, lr=6.72521e-05, gnorm=0.295, clip=0, loss_scale=16, train_wall=137, gb_free=22.6, wall=17968
2022-11-02 09:44:48 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
2022-11-02 09:46:17 | INFO | train_inner | epoch 014:  12885 / 16028 loss=2.957, nll_loss=0.997, nll_loss_teacher=0.543, kd_loss=3.248, ppl=2, wps=32455.9, ups=0.72, wpb=45197.1, bsz=3248.8, num_updates=221200, lr=6.72369e-05, gnorm=0.302, clip=0, loss_scale=8, train_wall=139, gb_free=16.8, wall=18107
2022-11-02 09:48:33 | INFO | train_inner | epoch 014:  12985 / 16028 loss=2.963, nll_loss=0.999, nll_loss_teacher=0.544, kd_loss=3.258, ppl=2, wps=33075.4, ups=0.74, wpb=44944.3, bsz=2984.8, num_updates=221300, lr=6.72217e-05, gnorm=0.304, clip=0, loss_scale=8, train_wall=136, gb_free=21.3, wall=18243
2022-11-02 09:50:50 | INFO | train_inner | epoch 014:  13085 / 16028 loss=2.959, nll_loss=0.997, nll_loss_teacher=0.543, kd_loss=3.255, ppl=2, wps=33254.8, ups=0.73, wpb=45595.4, bsz=3053.4, num_updates=221400, lr=6.72065e-05, gnorm=0.308, clip=0, loss_scale=8, train_wall=137, gb_free=19.6, wall=18380
2022-11-02 09:53:04 | INFO | train_inner | epoch 014:  13185 / 16028 loss=2.944, nll_loss=0.983, nll_loss_teacher=0.541, kd_loss=3.237, ppl=1.98, wps=34485.5, ups=0.74, wpb=46303.8, bsz=3195.9, num_updates=221500, lr=6.71913e-05, gnorm=0.281, clip=0, loss_scale=8, train_wall=134, gb_free=24.9, wall=18514
2022-11-02 09:55:19 | INFO | train_inner | epoch 014:  13285 / 16028 loss=2.96, nll_loss=0.998, nll_loss_teacher=0.544, kd_loss=3.253, ppl=2, wps=34138.6, ups=0.74, wpb=45936.2, bsz=3091.5, num_updates=221600, lr=6.71762e-05, gnorm=0.3, clip=0, loss_scale=8, train_wall=134, gb_free=21.4, wall=18649
2022-11-02 09:57:36 | INFO | train_inner | epoch 014:  13385 / 16028 loss=2.954, nll_loss=0.995, nll_loss_teacher=0.538, kd_loss=3.239, ppl=1.99, wps=33986.6, ups=0.73, wpb=46548.3, bsz=3158.8, num_updates=221700, lr=6.7161e-05, gnorm=0.295, clip=0, loss_scale=8, train_wall=137, gb_free=25.1, wall=18786
2022-11-02 09:59:53 | INFO | train_inner | epoch 014:  13485 / 16028 loss=2.963, nll_loss=1.004, nll_loss_teacher=0.541, kd_loss=3.251, ppl=2.01, wps=33382.9, ups=0.73, wpb=45586.7, bsz=3255.5, num_updates=221800, lr=6.71459e-05, gnorm=0.315, clip=0, loss_scale=8, train_wall=136, gb_free=27.4, wall=18922
2022-11-02 10:02:09 | INFO | train_inner | epoch 014:  13585 / 16028 loss=2.953, nll_loss=0.993, nll_loss_teacher=0.539, kd_loss=3.239, ppl=1.99, wps=33537, ups=0.73, wpb=45640.1, bsz=2998.8, num_updates=221900, lr=6.71307e-05, gnorm=0.297, clip=0, loss_scale=8, train_wall=136, gb_free=20.5, wall=19058
2022-11-02 10:04:25 | INFO | train_inner | epoch 014:  13685 / 16028 loss=2.96, nll_loss=0.997, nll_loss_teacher=0.545, kd_loss=3.259, ppl=2, wps=33674.7, ups=0.74, wpb=45802.2, bsz=3171.5, num_updates=222000, lr=6.71156e-05, gnorm=0.303, clip=0, loss_scale=8, train_wall=136, gb_free=23.3, wall=19194
2022-11-02 10:06:41 | INFO | train_inner | epoch 014:  13785 / 16028 loss=2.949, nll_loss=0.989, nll_loss_teacher=0.542, kd_loss=3.243, ppl=1.98, wps=33436.8, ups=0.74, wpb=45465.4, bsz=3327, num_updates=222100, lr=6.71005e-05, gnorm=0.296, clip=0, loss_scale=8, train_wall=136, gb_free=23, wall=19330
2022-11-02 10:08:57 | INFO | train_inner | epoch 014:  13885 / 16028 loss=2.948, nll_loss=0.988, nll_loss_teacher=0.538, kd_loss=3.236, ppl=1.98, wps=33598.6, ups=0.73, wpb=45823.2, bsz=3163, num_updates=222200, lr=6.70854e-05, gnorm=0.295, clip=0, loss_scale=8, train_wall=136, gb_free=23.5, wall=19467
2022-11-02 10:11:13 | INFO | train_inner | epoch 014:  13985 / 16028 loss=2.96, nll_loss=0.997, nll_loss_teacher=0.546, kd_loss=3.256, ppl=2, wps=33720, ups=0.73, wpb=45955.3, bsz=2978.5, num_updates=222300, lr=6.70703e-05, gnorm=0.307, clip=0, loss_scale=8, train_wall=136, gb_free=16.9, wall=19603
2022-11-02 10:13:28 | INFO | train_inner | epoch 014:  14085 / 16028 loss=2.96, nll_loss=0.998, nll_loss_teacher=0.543, kd_loss=3.255, ppl=2, wps=34789.4, ups=0.74, wpb=46943.2, bsz=3069.9, num_updates=222400, lr=6.70552e-05, gnorm=0.299, clip=0, loss_scale=8, train_wall=135, gb_free=21.8, wall=19738
2022-11-02 10:15:45 | INFO | train_inner | epoch 014:  14185 / 16028 loss=2.96, nll_loss=0.998, nll_loss_teacher=0.544, kd_loss=3.256, ppl=2, wps=33122.5, ups=0.73, wpb=45312.3, bsz=3011.3, num_updates=222500, lr=6.70402e-05, gnorm=0.295, clip=0, loss_scale=8, train_wall=137, gb_free=22, wall=19875
2022-11-02 10:18:01 | INFO | train_inner | epoch 014:  14285 / 16028 loss=2.945, nll_loss=0.983, nll_loss_teacher=0.542, kd_loss=3.24, ppl=1.98, wps=34378.6, ups=0.74, wpb=46665.5, bsz=3160.2, num_updates=222600, lr=6.70251e-05, gnorm=0.286, clip=0, loss_scale=8, train_wall=136, gb_free=24.2, wall=20010
2022-11-02 10:20:17 | INFO | train_inner | epoch 014:  14385 / 16028 loss=2.966, nll_loss=1.004, nll_loss_teacher=0.541, kd_loss=3.253, ppl=2.01, wps=33088.6, ups=0.73, wpb=45160.6, bsz=2913.8, num_updates=222700, lr=6.701e-05, gnorm=0.305, clip=0, loss_scale=8, train_wall=136, gb_free=21.7, wall=20147
2022-11-02 10:22:31 | INFO | train_inner | epoch 014:  14485 / 16028 loss=2.956, nll_loss=0.997, nll_loss_teacher=0.542, kd_loss=3.246, ppl=2, wps=35086.7, ups=0.75, wpb=46910, bsz=3122.8, num_updates=222800, lr=6.6995e-05, gnorm=0.299, clip=0, loss_scale=8, train_wall=134, gb_free=20, wall=20281
2022-11-02 10:24:47 | INFO | train_inner | epoch 014:  14585 / 16028 loss=2.958, nll_loss=0.995, nll_loss_teacher=0.545, kd_loss=3.26, ppl=1.99, wps=32637.3, ups=0.73, wpb=44490.6, bsz=3143.6, num_updates=222900, lr=6.698e-05, gnorm=0.302, clip=0, loss_scale=8, train_wall=136, gb_free=20.9, wall=20417
2022-11-02 10:27:03 | INFO | train_inner | epoch 014:  14685 / 16028 loss=2.956, nll_loss=0.993, nll_loss_teacher=0.547, kd_loss=3.257, ppl=1.99, wps=33623.7, ups=0.74, wpb=45603.5, bsz=3086.5, num_updates=223000, lr=6.6965e-05, gnorm=0.294, clip=0, loss_scale=8, train_wall=135, gb_free=16.6, wall=20553
2022-11-02 10:29:20 | INFO | train_inner | epoch 014:  14785 / 16028 loss=2.957, nll_loss=0.996, nll_loss_teacher=0.542, kd_loss=3.25, ppl=1.99, wps=33457.1, ups=0.73, wpb=45982.9, bsz=3081.7, num_updates=223100, lr=6.69499e-05, gnorm=0.293, clip=0, loss_scale=8, train_wall=137, gb_free=19.3, wall=20690
2022-11-02 10:31:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
2022-11-02 10:31:38 | INFO | train_inner | epoch 014:  14886 / 16028 loss=2.954, nll_loss=0.992, nll_loss_teacher=0.542, kd_loss=3.244, ppl=1.99, wps=33449.2, ups=0.72, wpb=46191.6, bsz=3161.2, num_updates=223200, lr=6.69349e-05, gnorm=0.302, clip=0, loss_scale=4, train_wall=138, gb_free=22.9, wall=20828
2022-11-02 10:33:55 | INFO | train_inner | epoch 014:  14986 / 16028 loss=2.96, nll_loss=0.996, nll_loss_teacher=0.547, kd_loss=3.265, ppl=1.99, wps=33483.2, ups=0.73, wpb=45600.3, bsz=3063, num_updates=223300, lr=6.692e-05, gnorm=0.307, clip=0, loss_scale=4, train_wall=136, gb_free=23.8, wall=20964
2022-11-02 10:36:10 | INFO | train_inner | epoch 014:  15086 / 16028 loss=2.957, nll_loss=0.996, nll_loss_teacher=0.544, kd_loss=3.254, ppl=1.99, wps=34187.4, ups=0.74, wpb=46338.3, bsz=3194.5, num_updates=223400, lr=6.6905e-05, gnorm=0.309, clip=0, loss_scale=4, train_wall=135, gb_free=20.7, wall=21100
2022-11-02 10:38:24 | INFO | train_inner | epoch 014:  15186 / 16028 loss=2.956, nll_loss=0.997, nll_loss_teacher=0.541, kd_loss=3.246, ppl=2, wps=34781.8, ups=0.75, wpb=46407, bsz=3034.8, num_updates=223500, lr=6.689e-05, gnorm=0.292, clip=0, loss_scale=4, train_wall=133, gb_free=24, wall=21233
2022-11-02 10:40:36 | INFO | train_inner | epoch 014:  15286 / 16028 loss=2.959, nll_loss=0.997, nll_loss_teacher=0.546, kd_loss=3.252, ppl=2, wps=34573.1, ups=0.75, wpb=45901.6, bsz=3077.7, num_updates=223600, lr=6.6875e-05, gnorm=0.298, clip=0, loss_scale=4, train_wall=133, gb_free=20.5, wall=21366
2022-11-02 10:42:53 | INFO | train_inner | epoch 014:  15386 / 16028 loss=2.957, nll_loss=0.994, nll_loss_teacher=0.544, kd_loss=3.256, ppl=1.99, wps=33773.1, ups=0.73, wpb=46170, bsz=2906.6, num_updates=223700, lr=6.68601e-05, gnorm=0.29, clip=0, loss_scale=4, train_wall=137, gb_free=29.6, wall=21503
2022-11-02 10:45:10 | INFO | train_inner | epoch 014:  15486 / 16028 loss=2.954, nll_loss=0.993, nll_loss_teacher=0.539, kd_loss=3.241, ppl=1.99, wps=33854.7, ups=0.73, wpb=46458.5, bsz=2975.4, num_updates=223800, lr=6.68452e-05, gnorm=0.307, clip=0, loss_scale=4, train_wall=137, gb_free=19.5, wall=21640
2022-11-02 10:47:26 | INFO | train_inner | epoch 014:  15586 / 16028 loss=2.954, nll_loss=0.993, nll_loss_teacher=0.542, kd_loss=3.247, ppl=1.99, wps=33984.4, ups=0.74, wpb=46125.2, bsz=3171.1, num_updates=223900, lr=6.68302e-05, gnorm=0.297, clip=0, loss_scale=4, train_wall=136, gb_free=28.5, wall=21776
2022-11-02 10:49:43 | INFO | train_inner | epoch 014:  15686 / 16028 loss=2.954, nll_loss=0.993, nll_loss_teacher=0.544, kd_loss=3.246, ppl=1.99, wps=33509.8, ups=0.73, wpb=45994.8, bsz=3181.3, num_updates=224000, lr=6.68153e-05, gnorm=0.295, clip=0, loss_scale=4, train_wall=137, gb_free=17.4, wall=21913
2022-11-02 10:52:00 | INFO | train_inner | epoch 014:  15786 / 16028 loss=2.955, nll_loss=0.996, nll_loss_teacher=0.541, kd_loss=3.248, ppl=1.99, wps=33633.3, ups=0.73, wpb=46135.1, bsz=3198.1, num_updates=224100, lr=6.68004e-05, gnorm=0.295, clip=0, loss_scale=4, train_wall=137, gb_free=22, wall=22050
2022-11-02 10:54:17 | INFO | train_inner | epoch 014:  15886 / 16028 loss=2.951, nll_loss=0.99, nll_loss_teacher=0.543, kd_loss=3.25, ppl=1.99, wps=33145.2, ups=0.73, wpb=45251.7, bsz=3263.5, num_updates=224200, lr=6.67855e-05, gnorm=0.294, clip=0, loss_scale=4, train_wall=136, gb_free=21.1, wall=22187
2022-11-02 10:56:32 | INFO | train_inner | epoch 014:  15986 / 16028 loss=2.962, nll_loss=0.997, nll_loss_teacher=0.546, kd_loss=3.265, ppl=2, wps=33639.9, ups=0.74, wpb=45527.6, bsz=2894.8, num_updates=224300, lr=6.67706e-05, gnorm=0.302, clip=0, loss_scale=4, train_wall=135, gb_free=21.7, wall=22322
2022-11-02 10:57:32 | INFO | fairseq_cli.train | begin validation on "valid" subset
2022-11-02 11:01:53 | INFO | valid | epoch 014 | valid on 'valid' subset | loss 5.148 | nll_loss 2.92 | nll_loss_teacher 2.67 | kd_loss 4.511 | ppl 7.57 | wps 46339.4 | wpb 34870.6 | bsz 2819.3 | num_updates 224342 | best_loss 5.142
2022-11-02 11:01:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 224342 updates
2022-11-02 11:01:53 | INFO | fairseq.trainer | Saving checkpoint to /nlsasfs/home/ai4bharat/yashkm/varun/Indic-En-Distillation/checkpoints/adaptive-distil/checkpoint14.pt
2022-11-02 11:01:55 | INFO | fairseq.trainer | Finished saving checkpoint to /nlsasfs/home/ai4bharat/yashkm/varun/Indic-En-Distillation/checkpoints/adaptive-distil/checkpoint14.pt
2022-11-02 11:01:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/adaptive-distil/checkpoint14.pt (epoch 14 @ 224342 updates, score 5.148) (writing took 4.303852703422308 seconds)
2022-11-02 11:01:57 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2022-11-02 11:01:57 | INFO | train | epoch 014 | loss 2.956 | nll_loss 0.995 | nll_loss_teacher 0.543 | kd_loss 3.25 | ppl 1.99 | wps 33243.3 | ups 0.73 | wpb 45830.8 | bsz 3104.2 | num_updates 224342 | lr 6.67644e-05 | gnorm 0.299 | clip 0 | loss_scale 4 | train_wall 21798 | gb_free 22.6 | wall 22647
2022-11-02 11:01:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 16028
2022-11-02 11:01:57 | INFO | fairseq.trainer | begin training epoch 15
2022-11-02 11:01:57 | INFO | fairseq_cli.train | Start iterating over samples
2022-11-02 11:10:08 | INFO | train_inner | epoch 015:     58 / 16028 loss=2.959, nll_loss=0.998, nll_loss_teacher=0.539, kd_loss=3.242, ppl=2, wps=5699, ups=0.12, wpb=46510.3, bsz=2893.5, num_updates=224400, lr=6.67557e-05, gnorm=0.307, clip=0, loss_scale=4, train_wall=134, gb_free=18.9, wall=23138
2022-11-02 11:12:14 | INFO | train_inner | epoch 015:    158 / 16028 loss=2.957, nll_loss=0.993, nll_loss_teacher=0.543, kd_loss=3.25, ppl=1.99, wps=35843.4, ups=0.8, wpb=45004.7, bsz=2986.1, num_updates=224500, lr=6.67409e-05, gnorm=0.314, clip=0, loss_scale=4, train_wall=125, gb_free=21.1, wall=23264
2022-11-02 11:14:26 | INFO | train_inner | epoch 015:    258 / 16028 loss=2.946, nll_loss=0.984, nll_loss_teacher=0.54, kd_loss=3.241, ppl=1.98, wps=35030.4, ups=0.76, wpb=46226, bsz=3185, num_updates=224600, lr=6.6726e-05, gnorm=0.292, clip=0, loss_scale=4, train_wall=132, gb_free=19.6, wall=23396
2022-11-02 11:16:33 | INFO | train_inner | epoch 015:    358 / 16028 loss=2.95, nll_loss=0.986, nll_loss_teacher=0.542, kd_loss=3.246, ppl=1.98, wps=36032.8, ups=0.79, wpb=45749.9, bsz=2991.9, num_updates=224700, lr=6.67112e-05, gnorm=0.29, clip=0, loss_scale=4, train_wall=127, gb_free=23.3, wall=23523
2022-11-02 11:19:44 | INFO | train_inner | epoch 015:    458 / 16028 loss=2.947, nll_loss=0.985, nll_loss_teacher=0.539, kd_loss=3.237, ppl=1.98, wps=24037.4, ups=0.52, wpb=46019.8, bsz=3060.2, num_updates=224800, lr=6.66963e-05, gnorm=0.294, clip=0, loss_scale=4, train_wall=191, gb_free=23, wall=23714
2022-11-02 11:21:57 | INFO | train_inner | epoch 015:    558 / 16028 loss=2.939, nll_loss=0.978, nll_loss_teacher=0.538, kd_loss=3.23, ppl=1.97, wps=34652.7, ups=0.76, wpb=45810.7, bsz=3362.7, num_updates=224900, lr=6.66815e-05, gnorm=0.291, clip=0, loss_scale=4, train_wall=132, gb_free=20.8, wall=23846
2022-11-02 11:24:13 | INFO | train_inner | epoch 015:    658 / 16028 loss=2.948, nll_loss=0.98, nll_loss_teacher=0.544, kd_loss=3.243, ppl=1.97, wps=33922.1, ups=0.73, wpb=46374.5, bsz=2944.1, num_updates=225000, lr=6.66667e-05, gnorm=0.294, clip=0, loss_scale=4, train_wall=137, gb_free=20, wall=23983
2022-11-02 11:26:31 | INFO | train_inner | epoch 015:    758 / 16028 loss=2.959, nll_loss=0.996, nll_loss_teacher=0.543, kd_loss=3.252, ppl=1.99, wps=32969.5, ups=0.73, wpb=45233.3, bsz=3024, num_updates=225100, lr=6.66519e-05, gnorm=0.306, clip=0, loss_scale=4, train_wall=137, gb_free=24.2, wall=24120
2022-11-02 11:28:48 | INFO | train_inner | epoch 015:    858 / 16028 loss=2.948, nll_loss=0.984, nll_loss_teacher=0.542, kd_loss=3.246, ppl=1.98, wps=33558.2, ups=0.73, wpb=46092.9, bsz=3166.8, num_updates=225200, lr=6.66371e-05, gnorm=0.296, clip=0, loss_scale=4, train_wall=137, gb_free=24.2, wall=24257
2022-11-02 11:31:04 | INFO | train_inner | epoch 015:    958 / 16028 loss=2.957, nll_loss=0.993, nll_loss_teacher=0.542, kd_loss=3.251, ppl=1.99, wps=32643.1, ups=0.73, wpb=44562.7, bsz=2966.1, num_updates=225300, lr=6.66223e-05, gnorm=0.312, clip=0, loss_scale=4, train_wall=136, gb_free=23.8, wall=24394
2022-11-02 11:33:21 | INFO | train_inner | epoch 015:   1058 / 16028 loss=2.957, nll_loss=0.992, nll_loss_teacher=0.545, kd_loss=3.254, ppl=1.99, wps=33548, ups=0.73, wpb=45811, bsz=3051.6, num_updates=225400, lr=6.66075e-05, gnorm=0.306, clip=0, loss_scale=4, train_wall=136, gb_free=21.3, wall=24531
2022-11-02 11:35:41 | INFO | train_inner | epoch 015:   1158 / 16028 loss=2.941, nll_loss=0.977, nll_loss_teacher=0.543, kd_loss=3.243, ppl=1.97, wps=32613.2, ups=0.72, wpb=45521.8, bsz=3308.4, num_updates=225500, lr=6.65927e-05, gnorm=0.292, clip=0, loss_scale=4, train_wall=139, gb_free=21.1, wall=24670
2022-11-02 11:38:00 | INFO | train_inner | epoch 015:   1258 / 16028 loss=2.954, nll_loss=0.992, nll_loss_teacher=0.545, kd_loss=3.252, ppl=1.99, wps=31992, ups=0.72, wpb=44632.4, bsz=3236.5, num_updates=225600, lr=6.6578e-05, gnorm=0.307, clip=0, loss_scale=4, train_wall=139, gb_free=24.9, wall=24810
2022-11-02 11:40:17 | INFO | train_inner | epoch 015:   1358 / 16028 loss=2.955, nll_loss=0.993, nll_loss_teacher=0.54, kd_loss=3.241, ppl=1.99, wps=32638.3, ups=0.73, wpb=44725, bsz=2986.7, num_updates=225700, lr=6.65632e-05, gnorm=0.31, clip=0, loss_scale=4, train_wall=137, gb_free=22.9, wall=24947
2022-11-02 11:42:33 | INFO | train_inner | epoch 015:   1458 / 16028 loss=2.952, nll_loss=0.986, nll_loss_teacher=0.545, kd_loss=3.256, ppl=1.98, wps=33144.7, ups=0.74, wpb=45018.6, bsz=3079.8, num_updates=225800, lr=6.65485e-05, gnorm=0.3, clip=0, loss_scale=4, train_wall=136, gb_free=21, wall=25083
2022-11-02 11:44:50 | INFO | train_inner | epoch 015:   1558 / 16028 loss=2.96, nll_loss=0.996, nll_loss_teacher=0.542, kd_loss=3.254, ppl=2, wps=32854.1, ups=0.73, wpb=45010.7, bsz=3009.9, num_updates=225900, lr=6.65337e-05, gnorm=0.306, clip=0, loss_scale=4, train_wall=137, gb_free=20.6, wall=25220
2022-11-02 11:47:06 | INFO | train_inner | epoch 015:   1658 / 16028 loss=2.947, nll_loss=0.985, nll_loss_teacher=0.541, kd_loss=3.237, ppl=1.98, wps=33609.2, ups=0.73, wpb=45785.9, bsz=3239, num_updates=226000, lr=6.6519e-05, gnorm=0.302, clip=0, loss_scale=4, train_wall=136, gb_free=18.7, wall=25356
2022-11-02 11:49:22 | INFO | train_inner | epoch 015:   1758 / 16028 loss=2.954, nll_loss=0.99, nll_loss_teacher=0.543, kd_loss=3.254, ppl=1.99, wps=34044.2, ups=0.74, wpb=46097.5, bsz=3076.6, num_updates=226100, lr=6.65043e-05, gnorm=0.296, clip=0, loss_scale=4, train_wall=135, gb_free=24.1, wall=25491
2022-11-02 11:51:35 | INFO | train_inner | epoch 015:   1858 / 16028 loss=2.951, nll_loss=0.989, nll_loss_teacher=0.539, kd_loss=3.24, ppl=1.98, wps=34096.3, ups=0.75, wpb=45460.8, bsz=3053, num_updates=226200, lr=6.64896e-05, gnorm=0.303, clip=0, loss_scale=4, train_wall=133, gb_free=23.5, wall=25624
2022-11-02 11:53:48 | INFO | train_inner | epoch 015:   1958 / 16028 loss=2.951, nll_loss=0.987, nll_loss_teacher=0.548, kd_loss=3.252, ppl=1.98, wps=34435.2, ups=0.75, wpb=45907.6, bsz=3065, num_updates=226300, lr=6.64749e-05, gnorm=0.289, clip=0, loss_scale=4, train_wall=133, gb_free=28.9, wall=25758
2022-11-02 11:56:04 | INFO | train_inner | epoch 015:   2058 / 16028 loss=2.943, nll_loss=0.98, nll_loss_teacher=0.541, kd_loss=3.24, ppl=1.97, wps=34228.7, ups=0.74, wpb=46355.6, bsz=3158.9, num_updates=226400, lr=6.64602e-05, gnorm=0.296, clip=0, loss_scale=4, train_wall=135, gb_free=22.9, wall=25893
2022-11-02 11:58:18 | INFO | train_inner | epoch 015:   2158 / 16028 loss=2.95, nll_loss=0.987, nll_loss_teacher=0.543, kd_loss=3.249, ppl=1.98, wps=34113, ups=0.75, wpb=45776.8, bsz=3207.7, num_updates=226500, lr=6.64455e-05, gnorm=0.305, clip=0, loss_scale=4, train_wall=134, gb_free=17.6, wall=26027
2022-11-02 12:00:35 | INFO | train_inner | epoch 015:   2258 / 16028 loss=2.948, nll_loss=0.986, nll_loss_teacher=0.541, kd_loss=3.243, ppl=1.98, wps=33519.3, ups=0.73, wpb=45887, bsz=3180.8, num_updates=226600, lr=6.64309e-05, gnorm=0.297, clip=0, loss_scale=4, train_wall=137, gb_free=21.6, wall=26164
2022-11-02 12:02:51 | INFO | train_inner | epoch 015:   2358 / 16028 loss=2.949, nll_loss=0.984, nll_loss_teacher=0.542, kd_loss=3.243, ppl=1.98, wps=33710.9, ups=0.73, wpb=45874, bsz=2990.8, num_updates=226700, lr=6.64162e-05, gnorm=0.304, clip=0, loss_scale=4, train_wall=136, gb_free=24.6, wall=26300
2022-11-02 12:05:03 | INFO | train_inner | epoch 015:   2458 / 16028 loss=2.947, nll_loss=0.984, nll_loss_teacher=0.542, kd_loss=3.246, ppl=1.98, wps=34633.7, ups=0.76, wpb=45791.6, bsz=3206.5, num_updates=226800, lr=6.64016e-05, gnorm=0.294, clip=0, loss_scale=4, train_wall=132, gb_free=25.6, wall=26433
2022-11-02 12:07:19 | INFO | train_inner | epoch 015:   2558 / 16028 loss=2.951, nll_loss=0.991, nll_loss_teacher=0.538, kd_loss=3.235, ppl=1.99, wps=33637.5, ups=0.73, wpb=45827.8, bsz=3065.3, num_updates=226900, lr=6.6387e-05, gnorm=0.305, clip=0, loss_scale=4, train_wall=136, gb_free=26.3, wall=26569
2022-11-02 12:09:36 | INFO | train_inner | epoch 015:   2658 / 16028 loss=2.952, nll_loss=0.99, nll_loss_teacher=0.54, kd_loss=3.24, ppl=1.99, wps=33927.1, ups=0.73, wpb=46449.4, bsz=3067.8, num_updates=227000, lr=6.63723e-05, gnorm=0.301, clip=0, loss_scale=4, train_wall=137, gb_free=20.6, wall=26706
2022-11-02 12:11:52 | INFO | train_inner | epoch 015:   2758 / 16028 loss=2.952, nll_loss=0.989, nll_loss_teacher=0.543, kd_loss=3.249, ppl=1.98, wps=33507.4, ups=0.74, wpb=45511.7, bsz=3097.6, num_updates=227100, lr=6.63577e-05, gnorm=0.294, clip=0, loss_scale=4, train_wall=136, gb_free=24.2, wall=26842
2022-11-02 12:14:09 | INFO | train_inner | epoch 015:   2858 / 16028 loss=2.95, nll_loss=0.985, nll_loss_teacher=0.544, kd_loss=3.248, ppl=1.98, wps=33490.6, ups=0.73, wpb=45749.9, bsz=3176.9, num_updates=227200, lr=6.63431e-05, gnorm=0.291, clip=0, loss_scale=4, train_wall=136, gb_free=19.1, wall=26978
2022-11-02 12:16:25 | INFO | train_inner | epoch 015:   2958 / 16028 loss=2.964, nll_loss=1.001, nll_loss_teacher=0.544, kd_loss=3.257, ppl=2, wps=33595.4, ups=0.73, wpb=45952.3, bsz=3159.9, num_updates=227300, lr=6.63285e-05, gnorm=0.321, clip=0, loss_scale=8, train_wall=137, gb_free=22.5, wall=27115
2022-11-02 12:18:41 | INFO | train_inner | epoch 015:   3058 / 16028 loss=2.955, nll_loss=0.992, nll_loss_teacher=0.545, kd_loss=3.25, ppl=1.99, wps=34111.8, ups=0.74, wpb=46254.1, bsz=3093.8, num_updates=227400, lr=6.63139e-05, gnorm=0.296, clip=0, loss_scale=8, train_wall=135, gb_free=22.9, wall=27251
2022-11-02 12:20:56 | INFO | train_inner | epoch 015:   3158 / 16028 loss=2.952, nll_loss=0.986, nll_loss_teacher=0.546, kd_loss=3.256, ppl=1.98, wps=34080.2, ups=0.74, wpb=45916, bsz=3136.6, num_updates=227500, lr=6.62994e-05, gnorm=0.295, clip=0, loss_scale=8, train_wall=135, gb_free=22.3, wall=27385
2022-11-02 12:23:12 | INFO | train_inner | epoch 015:   3258 / 16028 loss=2.951, nll_loss=0.988, nll_loss_teacher=0.541, kd_loss=3.244, ppl=1.98, wps=33832.3, ups=0.73, wpb=46223.4, bsz=2983.1, num_updates=227600, lr=6.62848e-05, gnorm=0.289, clip=0, loss_scale=8, train_wall=136, gb_free=21.4, wall=27522
2022-11-02 12:25:30 | INFO | train_inner | epoch 015:   3358 / 16028 loss=2.952, nll_loss=0.989, nll_loss_teacher=0.543, kd_loss=3.25, ppl=1.99, wps=33580, ups=0.73, wpb=46127.7, bsz=3146.4, num_updates=227700, lr=6.62702e-05, gnorm=0.29, clip=0, loss_scale=8, train_wall=137, gb_free=20.2, wall=27659
2022-11-02 12:27:48 | INFO | train_inner | epoch 015:   3458 / 16028 loss=2.958, nll_loss=0.995, nll_loss_teacher=0.543, kd_loss=3.252, ppl=1.99, wps=33034.9, ups=0.72, wpb=45809.1, bsz=2971.8, num_updates=227800, lr=6.62557e-05, gnorm=0.291, clip=0, loss_scale=8, train_wall=138, gb_free=19.9, wall=27798
2022-11-02 12:30:06 | INFO | train_inner | epoch 015:   3558 / 16028 loss=2.953, nll_loss=0.991, nll_loss_teacher=0.542, kd_loss=3.247, ppl=1.99, wps=33469.1, ups=0.73, wpb=45956.8, bsz=3168.4, num_updates=227900, lr=6.62411e-05, gnorm=0.306, clip=0, loss_scale=8, train_wall=137, gb_free=16.7, wall=27935
2022-11-02 12:32:21 | INFO | train_inner | epoch 015:   3658 / 16028 loss=2.955, nll_loss=0.991, nll_loss_teacher=0.542, kd_loss=3.251, ppl=1.99, wps=33572.8, ups=0.74, wpb=45554.9, bsz=2920.2, num_updates=228000, lr=6.62266e-05, gnorm=0.3, clip=0, loss_scale=8, train_wall=135, gb_free=25.3, wall=28071
2022-11-02 12:34:38 | INFO | train_inner | epoch 015:   3758 / 16028 loss=2.946, nll_loss=0.985, nll_loss_teacher=0.54, kd_loss=3.234, ppl=1.98, wps=33125.5, ups=0.73, wpb=45373.8, bsz=3124.2, num_updates=228100, lr=6.62121e-05, gnorm=0.294, clip=0, loss_scale=8, train_wall=137, gb_free=21.3, wall=28208
2022-11-02 12:36:56 | INFO | train_inner | epoch 015:   3858 / 16028 loss=2.961, nll_loss=0.996, nll_loss_teacher=0.544, kd_loss=3.257, ppl=1.99, wps=33409.5, ups=0.73, wpb=45902.5, bsz=2993, num_updates=228200, lr=6.61976e-05, gnorm=0.302, clip=0, loss_scale=8, train_wall=137, gb_free=20.7, wall=28345
2022-11-02 12:39:11 | INFO | train_inner | epoch 015:   3958 / 16028 loss=2.953, nll_loss=0.99, nll_loss_teacher=0.542, kd_loss=3.242, ppl=1.99, wps=33787.1, ups=0.74, wpb=45751, bsz=3039.9, num_updates=228300, lr=6.61831e-05, gnorm=0.295, clip=0, loss_scale=8, train_wall=135, gb_free=23.3, wall=28481
2022-11-02 12:41:27 | INFO | train_inner | epoch 015:   4058 / 16028 loss=2.952, nll_loss=0.988, nll_loss_teacher=0.543, kd_loss=3.248, ppl=1.98, wps=33036.9, ups=0.73, wpb=44985.9, bsz=3130.6, num_updates=228400, lr=6.61686e-05, gnorm=0.302, clip=0, loss_scale=8, train_wall=136, gb_free=27.7, wall=28617
2022-11-02 12:43:45 | INFO | train_inner | epoch 015:   4158 / 16028 loss=2.95, nll_loss=0.985, nll_loss_teacher=0.541, kd_loss=3.24, ppl=1.98, wps=33402.5, ups=0.73, wpb=45892.5, bsz=2934.1, num_updates=228500, lr=6.61541e-05, gnorm=0.298, clip=0, loss_scale=8, train_wall=137, gb_free=24.5, wall=28754
2022-11-02 12:46:01 | INFO | train_inner | epoch 015:   4258 / 16028 loss=2.95, nll_loss=0.987, nll_loss_teacher=0.541, kd_loss=3.241, ppl=1.98, wps=33488.4, ups=0.73, wpb=45792.4, bsz=3012.2, num_updates=228600, lr=6.61396e-05, gnorm=0.291, clip=0, loss_scale=8, train_wall=137, gb_free=24.7, wall=28891
2022-11-02 12:48:18 | INFO | train_inner | epoch 015:   4358 / 16028 loss=2.939, nll_loss=0.978, nll_loss_teacher=0.542, kd_loss=3.241, ppl=1.97, wps=33621.2, ups=0.73, wpb=45934.1, bsz=3366.1, num_updates=228700, lr=6.61252e-05, gnorm=0.29, clip=0, loss_scale=8, train_wall=136, gb_free=22.6, wall=29028
2022-11-02 12:50:35 | INFO | train_inner | epoch 015:   4458 / 16028 loss=2.963, nll_loss=1, nll_loss_teacher=0.541, kd_loss=3.25, ppl=2, wps=33869, ups=0.73, wpb=46328.2, bsz=3205.4, num_updates=228800, lr=6.61107e-05, gnorm=0.33, clip=1, loss_scale=8, train_wall=137, gb_free=16.9, wall=29165
2022-11-02 12:52:51 | INFO | train_inner | epoch 015:   4558 / 16028 loss=2.947, nll_loss=0.986, nll_loss_teacher=0.542, kd_loss=3.239, ppl=1.98, wps=34087.7, ups=0.73, wpb=46531.6, bsz=3140.8, num_updates=228900, lr=6.60963e-05, gnorm=0.281, clip=0, loss_scale=8, train_wall=136, gb_free=20.6, wall=29301
2022-11-02 12:55:08 | INFO | train_inner | epoch 015:   4658 / 16028 loss=2.955, nll_loss=0.992, nll_loss_teacher=0.543, kd_loss=3.25, ppl=1.99, wps=34078.4, ups=0.73, wpb=46679.9, bsz=2999.2, num_updates=229000, lr=6.60819e-05, gnorm=0.292, clip=0, loss_scale=8, train_wall=137, gb_free=23.6, wall=29438
2022-11-02 12:57:26 | INFO | train_inner | epoch 015:   4758 / 16028 loss=2.953, nll_loss=0.99, nll_loss_teacher=0.543, kd_loss=3.244, ppl=1.99, wps=33628.1, ups=0.73, wpb=46274.8, bsz=3041.2, num_updates=229100, lr=6.60674e-05, gnorm=0.305, clip=0, loss_scale=8, train_wall=137, gb_free=22.6, wall=29576
2022-11-02 12:59:41 | INFO | train_inner | epoch 015:   4858 / 16028 loss=2.95, nll_loss=0.985, nll_loss_teacher=0.543, kd_loss=3.251, ppl=1.98, wps=33919.2, ups=0.74, wpb=45785.9, bsz=2945.6, num_updates=229200, lr=6.6053e-05, gnorm=0.292, clip=0, loss_scale=8, train_wall=135, gb_free=27.4, wall=29711
2022-11-02 13:01:58 | INFO | train_inner | epoch 015:   4958 / 16028 loss=2.947, nll_loss=0.983, nll_loss_teacher=0.544, kd_loss=3.244, ppl=1.98, wps=32964.6, ups=0.73, wpb=45117, bsz=3272.5, num_updates=229300, lr=6.60386e-05, gnorm=0.305, clip=0, loss_scale=8, train_wall=137, gb_free=19.7, wall=29847
2022-11-02 13:04:14 | INFO | train_inner | epoch 015:   5058 / 16028 loss=2.946, nll_loss=0.984, nll_loss_teacher=0.541, kd_loss=3.242, ppl=1.98, wps=33168.6, ups=0.73, wpb=45283.8, bsz=3163.9, num_updates=229400, lr=6.60242e-05, gnorm=0.287, clip=0, loss_scale=8, train_wall=136, gb_free=29.3, wall=29984
2022-11-02 13:06:30 | INFO | train_inner | epoch 015:   5158 / 16028 loss=2.959, nll_loss=0.997, nll_loss_teacher=0.544, kd_loss=3.252, ppl=2, wps=34046.6, ups=0.74, wpb=46120, bsz=2951.6, num_updates=229500, lr=6.60098e-05, gnorm=0.304, clip=0, loss_scale=8, train_wall=135, gb_free=16.9, wall=30119
2022-11-02 13:08:46 | INFO | train_inner | epoch 015:   5258 / 16028 loss=2.962, nll_loss=0.998, nll_loss_teacher=0.546, kd_loss=3.262, ppl=2, wps=33325.4, ups=0.73, wpb=45403.3, bsz=2950.1, num_updates=229600, lr=6.59955e-05, gnorm=0.307, clip=0, loss_scale=8, train_wall=136, gb_free=22.1, wall=30256
2022-11-02 13:11:02 | INFO | train_inner | epoch 015:   5358 / 16028 loss=2.942, nll_loss=0.98, nll_loss_teacher=0.542, kd_loss=3.238, ppl=1.97, wps=33847.1, ups=0.73, wpb=46050.5, bsz=3190.5, num_updates=229700, lr=6.59811e-05, gnorm=0.283, clip=0, loss_scale=8, train_wall=136, gb_free=21, wall=30392
2022-11-02 13:13:19 | INFO | train_inner | epoch 015:   5458 / 16028 loss=2.95, nll_loss=0.989, nll_loss_teacher=0.539, kd_loss=3.238, ppl=1.98, wps=33744.5, ups=0.73, wpb=46139.4, bsz=3117, num_updates=229800, lr=6.59667e-05, gnorm=0.294, clip=0, loss_scale=8, train_wall=137, gb_free=18.2, wall=30528
2022-11-02 13:15:35 | INFO | train_inner | epoch 015:   5558 / 16028 loss=2.944, nll_loss=0.981, nll_loss_teacher=0.54, kd_loss=3.234, ppl=1.97, wps=34079.6, ups=0.74, wpb=46271.3, bsz=3160.5, num_updates=229900, lr=6.59524e-05, gnorm=0.287, clip=0, loss_scale=8, train_wall=136, gb_free=19.1, wall=30664
2022-11-02 13:17:52 | INFO | train_inner | epoch 015:   5658 / 16028 loss=2.956, nll_loss=0.991, nll_loss_teacher=0.543, kd_loss=3.252, ppl=1.99, wps=33663.3, ups=0.73, wpb=46200.3, bsz=3028.5, num_updates=230000, lr=6.5938e-05, gnorm=0.297, clip=0, loss_scale=8, train_wall=137, gb_free=21.5, wall=30802
2022-11-02 13:20:06 | INFO | train_inner | epoch 015:   5758 / 16028 loss=2.952, nll_loss=0.989, nll_loss_teacher=0.541, kd_loss=3.243, ppl=1.99, wps=34145.7, ups=0.74, wpb=45963.5, bsz=3022.5, num_updates=230100, lr=6.59237e-05, gnorm=0.294, clip=0, loss_scale=8, train_wall=134, gb_free=28, wall=30936
2022-11-02 13:22:22 | INFO | train_inner | epoch 015:   5858 / 16028 loss=2.952, nll_loss=0.989, nll_loss_teacher=0.544, kd_loss=3.251, ppl=1.98, wps=33813.5, ups=0.74, wpb=45963.1, bsz=3132.2, num_updates=230200, lr=6.59094e-05, gnorm=0.304, clip=0, loss_scale=8, train_wall=136, gb_free=18.8, wall=31072
2022-11-02 13:24:39 | INFO | train_inner | epoch 015:   5958 / 16028 loss=2.953, nll_loss=0.992, nll_loss_teacher=0.54, kd_loss=3.236, ppl=1.99, wps=33411.1, ups=0.73, wpb=45794.2, bsz=3088.3, num_updates=230300, lr=6.58951e-05, gnorm=0.3, clip=0, loss_scale=8, train_wall=137, gb_free=21.7, wall=31209
2022-11-02 13:26:56 | INFO | train_inner | epoch 015:   6058 / 16028 loss=2.943, nll_loss=0.981, nll_loss_teacher=0.541, kd_loss=3.239, ppl=1.97, wps=33378.6, ups=0.73, wpb=45483.5, bsz=3275.8, num_updates=230400, lr=6.58808e-05, gnorm=0.293, clip=0, loss_scale=8, train_wall=136, gb_free=17.4, wall=31345
2022-11-02 13:29:12 | INFO | train_inner | epoch 015:   6158 / 16028 loss=2.959, nll_loss=0.994, nll_loss_teacher=0.546, kd_loss=3.26, ppl=1.99, wps=33201.6, ups=0.73, wpb=45295.2, bsz=3101, num_updates=230500, lr=6.58665e-05, gnorm=0.305, clip=0, loss_scale=8, train_wall=136, gb_free=25.6, wall=31482
2022-11-02 13:31:31 | INFO | train_inner | epoch 015:   6258 / 16028 loss=2.958, nll_loss=0.995, nll_loss_teacher=0.543, kd_loss=3.255, ppl=1.99, wps=32989.3, ups=0.72, wpb=45692, bsz=3176.5, num_updates=230600, lr=6.58522e-05, gnorm=0.302, clip=0, loss_scale=8, train_wall=138, gb_free=20.4, wall=31620
2022-11-02 13:33:48 | INFO | train_inner | epoch 015:   6358 / 16028 loss=2.954, nll_loss=0.991, nll_loss_teacher=0.543, kd_loss=3.25, ppl=1.99, wps=33803.3, ups=0.73, wpb=46473.3, bsz=3071.7, num_updates=230700, lr=6.58379e-05, gnorm=0.305, clip=0, loss_scale=8, train_wall=137, gb_free=23, wall=31758
2022-11-02 13:36:05 | INFO | train_inner | epoch 015:   6458 / 16028 loss=2.941, nll_loss=0.977, nll_loss_teacher=0.54, kd_loss=3.239, ppl=1.97, wps=33785.6, ups=0.73, wpb=46379.5, bsz=3124.7, num_updates=230800, lr=6.58237e-05, gnorm=0.289, clip=0, loss_scale=8, train_wall=137, gb_free=20.2, wall=31895
2022-11-02 13:38:22 | INFO | train_inner | epoch 015:   6558 / 16028 loss=2.949, nll_loss=0.985, nll_loss_teacher=0.542, kd_loss=3.245, ppl=1.98, wps=33501.8, ups=0.73, wpb=45664.2, bsz=3036.4, num_updates=230900, lr=6.58094e-05, gnorm=0.292, clip=0, loss_scale=8, train_wall=136, gb_free=24.9, wall=32031
2022-11-02 13:40:41 | INFO | train_inner | epoch 015:   6658 / 16028 loss=2.948, nll_loss=0.984, nll_loss_teacher=0.544, kd_loss=3.25, ppl=1.98, wps=33269, ups=0.72, wpb=46250.3, bsz=3307.9, num_updates=231000, lr=6.57952e-05, gnorm=0.296, clip=0, loss_scale=8, train_wall=139, gb_free=29, wall=32170
2022-11-02 13:43:00 | INFO | train_inner | epoch 015:   6758 / 16028 loss=2.951, nll_loss=0.988, nll_loss_teacher=0.541, kd_loss=3.243, ppl=1.98, wps=33303.3, ups=0.72, wpb=46210.8, bsz=2974.8, num_updates=231100, lr=6.57809e-05, gnorm=0.296, clip=0, loss_scale=8, train_wall=139, gb_free=24.2, wall=32309
2022-11-02 13:45:17 | INFO | train_inner | epoch 015:   6858 / 16028 loss=2.952, nll_loss=0.987, nll_loss_teacher=0.546, kd_loss=3.26, ppl=1.98, wps=32951.9, ups=0.73, wpb=45249.1, bsz=3239.8, num_updates=231200, lr=6.57667e-05, gnorm=0.306, clip=0, loss_scale=8, train_wall=137, gb_free=18, wall=32446
2022-11-02 13:47:33 | INFO | train_inner | epoch 015:   6958 / 16028 loss=2.956, nll_loss=0.992, nll_loss_teacher=0.544, kd_loss=3.253, ppl=1.99, wps=33727.8, ups=0.74, wpb=45834.1, bsz=3091.4, num_updates=231300, lr=6.57525e-05, gnorm=0.299, clip=0, loss_scale=8, train_wall=136, gb_free=16.7, wall=32582
2022-11-02 13:49:51 | INFO | train_inner | epoch 015:   7058 / 16028 loss=2.953, nll_loss=0.988, nll_loss_teacher=0.544, kd_loss=3.254, ppl=1.98, wps=33064.5, ups=0.72, wpb=45777.7, bsz=3065.5, num_updates=231400, lr=6.57383e-05, gnorm=0.292, clip=0, loss_scale=16, train_wall=138, gb_free=24.6, wall=32721
2022-11-02 13:52:09 | INFO | train_inner | epoch 015:   7158 / 16028 loss=2.951, nll_loss=0.991, nll_loss_teacher=0.54, kd_loss=3.242, ppl=1.99, wps=33537.5, ups=0.73, wpb=46166.8, bsz=3108.9, num_updates=231500, lr=6.57241e-05, gnorm=0.3, clip=0, loss_scale=16, train_wall=137, gb_free=17.6, wall=32858
2022-11-02 13:54:28 | INFO | train_inner | epoch 015:   7258 / 16028 loss=2.947, nll_loss=0.983, nll_loss_teacher=0.542, kd_loss=3.244, ppl=1.98, wps=33520.7, ups=0.72, wpb=46575.8, bsz=3037.4, num_updates=231600, lr=6.57099e-05, gnorm=0.29, clip=0, loss_scale=16, train_wall=139, gb_free=22.6, wall=32997
2022-11-02 13:56:46 | INFO | train_inner | epoch 015:   7358 / 16028 loss=2.96, nll_loss=0.997, nll_loss_teacher=0.543, kd_loss=3.254, ppl=2, wps=33066.5, ups=0.72, wpb=45621.9, bsz=2927.7, num_updates=231700, lr=6.56957e-05, gnorm=0.298, clip=0, loss_scale=16, train_wall=138, gb_free=21.3, wall=33135
2022-11-02 13:59:04 | INFO | train_inner | epoch 015:   7458 / 16028 loss=2.947, nll_loss=0.984, nll_loss_teacher=0.541, kd_loss=3.239, ppl=1.98, wps=33126.7, ups=0.72, wpb=45792.3, bsz=3101, num_updates=231800, lr=6.56815e-05, gnorm=0.304, clip=0, loss_scale=16, train_wall=138, gb_free=23.2, wall=33274
2022-11-02 14:01:20 | INFO | train_inner | epoch 015:   7558 / 16028 loss=2.948, nll_loss=0.987, nll_loss_teacher=0.54, kd_loss=3.237, ppl=1.98, wps=34447.1, ups=0.73, wpb=46936.4, bsz=3143.4, num_updates=231900, lr=6.56674e-05, gnorm=0.298, clip=0, loss_scale=16, train_wall=136, gb_free=25.1, wall=33410
2022-11-02 14:03:39 | INFO | train_inner | epoch 015:   7658 / 16028 loss=2.951, nll_loss=0.988, nll_loss_teacher=0.546, kd_loss=3.245, ppl=1.98, wps=33209.9, ups=0.72, wpb=46169.5, bsz=2975.8, num_updates=232000, lr=6.56532e-05, gnorm=0.289, clip=0, loss_scale=16, train_wall=139, gb_free=22.7, wall=33549
2022-11-02 14:05:58 | INFO | train_inner | epoch 015:   7758 / 16028 loss=2.942, nll_loss=0.979, nll_loss_teacher=0.543, kd_loss=3.242, ppl=1.97, wps=33246.1, ups=0.72, wpb=46107.1, bsz=3321.7, num_updates=232100, lr=6.56391e-05, gnorm=0.287, clip=0, loss_scale=16, train_wall=139, gb_free=23.2, wall=33688
2022-11-02 14:08:16 | INFO | train_inner | epoch 015:   7858 / 16028 loss=2.949, nll_loss=0.988, nll_loss_teacher=0.541, kd_loss=3.241, ppl=1.98, wps=33781.4, ups=0.73, wpb=46538.7, bsz=3102.4, num_updates=232200, lr=6.56249e-05, gnorm=0.29, clip=0, loss_scale=16, train_wall=138, gb_free=29.8, wall=33825
2022-11-02 14:10:34 | INFO | train_inner | epoch 015:   7958 / 16028 loss=2.957, nll_loss=0.994, nll_loss_teacher=0.547, kd_loss=3.258, ppl=1.99, wps=33132.9, ups=0.72, wpb=45720.7, bsz=3127.2, num_updates=232300, lr=6.56108e-05, gnorm=0.298, clip=0, loss_scale=16, train_wall=138, gb_free=21.7, wall=33963
2022-11-02 14:12:52 | INFO | train_inner | epoch 015:   8058 / 16028 loss=2.959, nll_loss=0.998, nll_loss_teacher=0.546, kd_loss=3.251, ppl=2, wps=33072, ups=0.73, wpb=45601.9, bsz=3109.9, num_updates=232400, lr=6.55967e-05, gnorm=0.302, clip=0, loss_scale=16, train_wall=138, gb_free=26.5, wall=34101
2022-11-02 14:15:09 | INFO | train_inner | epoch 015:   8158 / 16028 loss=2.959, nll_loss=0.997, nll_loss_teacher=0.542, kd_loss=3.249, ppl=2, wps=32990.8, ups=0.73, wpb=45428.3, bsz=3053.2, num_updates=232500, lr=6.55826e-05, gnorm=0.306, clip=0, loss_scale=16, train_wall=138, gb_free=20, wall=34239
2022-11-02 14:17:27 | INFO | train_inner | epoch 015:   8258 / 16028 loss=2.959, nll_loss=0.996, nll_loss_teacher=0.545, kd_loss=3.254, ppl=1.99, wps=33350.3, ups=0.72, wpb=46030.6, bsz=2957.8, num_updates=232600, lr=6.55685e-05, gnorm=0.297, clip=0, loss_scale=16, train_wall=138, gb_free=19.3, wall=34377
2022-11-02 14:19:46 | INFO | train_inner | epoch 015:   8358 / 16028 loss=2.95, nll_loss=0.989, nll_loss_teacher=0.542, kd_loss=3.245, ppl=1.98, wps=32960.5, ups=0.72, wpb=45631.5, bsz=3225.9, num_updates=232700, lr=6.55544e-05, gnorm=0.296, clip=0, loss_scale=16, train_wall=138, gb_free=22.3, wall=34515
2022-11-02 14:22:00 | INFO | train_inner | epoch 015:   8458 / 16028 loss=2.952, nll_loss=0.988, nll_loss_teacher=0.545, kd_loss=3.25, ppl=1.98, wps=34814.2, ups=0.74, wpb=46751.6, bsz=3077.4, num_updates=232800, lr=6.55403e-05, gnorm=0.297, clip=0, loss_scale=16, train_wall=134, gb_free=19.6, wall=34650
2022-11-02 14:24:18 | INFO | train_inner | epoch 015:   8558 / 16028 loss=2.949, nll_loss=0.989, nll_loss_teacher=0.541, kd_loss=3.24, ppl=1.98, wps=33529.3, ups=0.73, wpb=46132.7, bsz=3181.3, num_updates=232900, lr=6.55262e-05, gnorm=0.297, clip=0, loss_scale=16, train_wall=137, gb_free=17.6, wall=34787
2022-11-02 14:26:35 | INFO | train_inner | epoch 015:   8658 / 16028 loss=2.953, nll_loss=0.992, nll_loss_teacher=0.54, kd_loss=3.242, ppl=1.99, wps=33037.2, ups=0.73, wpb=45309.4, bsz=3100.3, num_updates=233000, lr=6.55122e-05, gnorm=0.305, clip=0, loss_scale=16, train_wall=137, gb_free=19.3, wall=34924
2022-11-02 14:28:52 | INFO | train_inner | epoch 015:   8758 / 16028 loss=2.955, nll_loss=0.992, nll_loss_teacher=0.546, kd_loss=3.251, ppl=1.99, wps=33538.1, ups=0.73, wpb=46115.7, bsz=3064.1, num_updates=233100, lr=6.54981e-05, gnorm=0.294, clip=0, loss_scale=16, train_wall=137, gb_free=24.1, wall=35062
2022-11-02 14:31:11 | INFO | train_inner | epoch 015:   8858 / 16028 loss=2.955, nll_loss=0.992, nll_loss_teacher=0.543, kd_loss=3.25, ppl=1.99, wps=32661.5, ups=0.72, wpb=45322.2, bsz=3055.7, num_updates=233200, lr=6.54841e-05, gnorm=0.303, clip=0, loss_scale=16, train_wall=139, gb_free=22.8, wall=35201
2022-11-02 14:33:29 | INFO | train_inner | epoch 015:   8958 / 16028 loss=2.957, nll_loss=0.995, nll_loss_teacher=0.542, kd_loss=3.249, ppl=1.99, wps=33456.9, ups=0.72, wpb=46185, bsz=3084.8, num_updates=233300, lr=6.547e-05, gnorm=0.301, clip=0, loss_scale=16, train_wall=138, gb_free=21.4, wall=35339
2022-11-02 14:33:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
